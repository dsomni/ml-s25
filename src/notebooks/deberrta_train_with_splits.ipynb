{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kiaver\\PycharmProjects\\ml-s25\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from copy import deepcopy\n",
    "\n",
    "import datasets\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "from accelerate import Accelerator\n",
    "from accelerate.logging import get_logger\n",
    "from accelerate.utils import set_seed\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "sys.path.append(\"../scripts\")\n",
    "\n",
    "try:\n",
    "    from ai_dataset import AiDataset\n",
    "    from ai_loader import AiCollator, AiCollatorTrain\n",
    "    from ai_model import AiModel\n",
    "    from ai_optimizer import get_optimizer\n",
    "    from metric_utils import compute_metrics\n",
    "    from train_utils import AverageMeter, as_minutes, get_lr, save_checkpoint\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    raise ImportError\n",
    "\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "\n",
    "pd.options.display.max_colwidth = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c0df7d49-26f5-451c-b44a-1e0bca60bca5</td>\n",
       "      <td>\\r\\nn = 1\\r\\nwhile n:\\r\\n    n = int(input())\\r\\n    if n:\\r\\n        print(n+1)\\r\\n        break\\r\\n</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c0df7d49-26f5-451c-b44a-1e0bca60bca5</td>\n",
       "      <td>\\r\\ncount = 0\\r\\nnum = input()\\r\\nwhile num != '0':\\r\\n    count += 1\\r\\n    num = input()\\r\\nprint(count)\\r\\n</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c0df7d49-26f5-451c-b44a-1e0bca60bca5</td>\n",
       "      <td>sequence = []\\r\\nwhile True:\\r\\n    num = int(input())\\r\\n    if num == 0:\\r\\n        break\\r\\n    sequence.append(num)\\r\\n\\r\\nprint(len(sequence))</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4e5b21c0-e86f-4eac-82b6-1a0d00ae4199</td>\n",
       "      <td>a=[]\\r\\nwhile True:\\r\\n   b=input()\\r\\n   if b=='0':\\r\\n     break\\r\\n   a+=[int(b)]\\r\\nprint(a.count(max(a)))</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4e5b21c0-e86f-4eac-82b6-1a0d00ae4199</td>\n",
       "      <td>\\r\\nmax_val = float('-inf')\\r\\ncount = 0\\r\\n\\r\\nwhile True:\\r\\n    num = int(input())\\r\\n    if num == 0:\\r\\n        break\\r\\n    if num &gt; max_val:\\r\\n        max_val = num\\r\\n        count = 1\\r\\n    elif num == max_val:\\r\\n        count += 1\\r\\n\\r\\nprint(count)\\r\\n</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9246</th>\n",
       "      <td>49c03922-c57e-464a-8191-9ebef2615808</td>\n",
       "      <td>a, b, c = map(int, input().split())\\nif c &gt; a and c &gt; b:\\n    print(c //b + 1 + c// a + 1)\\nelif a == b == c:\\n    print(4)\\nelse:\\n    print(2)\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>9328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9247</th>\n",
       "      <td>2173e6e8-cca6-47c7-8ef6-ea93d3e736f4</td>\n",
       "      <td>n,*a=map(int,open(0).read().split())\\na=sorted(a)\\nd=[0]*n\\nd[0]=1e9\\nd[1]=a[1]-a[0]\\nfor i in range(2,n):\\n    d[i]=min(d[i-1]+a[i]-a[i-1],d[i-2]+a[i]-a[i-1])\\nprint(int(d[-1]))\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>9329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9248</th>\n",
       "      <td>2a42d873-b1fe-4256-a488-91db4eaa8d9f</td>\n",
       "      <td>n=list(input())\\nd=sorted(list(input()))\\nif max(d)&gt;min(n):\\n    p=-1\\n    for i in range(len(n)):\\n        if n[i]&lt;d[p]:\\n            n[i]=d[p]\\n            p-=1\\nprint(\"\".join(n))</td>\n",
       "      <td>0</td>\n",
       "      <td>9330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9249</th>\n",
       "      <td>48f237db-e593-4be6-b3f9-10757a1d07ec</td>\n",
       "      <td>a=int(input())\\nprint(a)</td>\n",
       "      <td>0</td>\n",
       "      <td>9331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9250</th>\n",
       "      <td>190516a0-6ed3-4c42-9f36-dc481a3adb70</td>\n",
       "      <td>a=int(input())\\nb=int(input())\\nprint(a+b)</td>\n",
       "      <td>0</td>\n",
       "      <td>9332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9251 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      task  \\\n",
       "0     c0df7d49-26f5-451c-b44a-1e0bca60bca5   \n",
       "1     c0df7d49-26f5-451c-b44a-1e0bca60bca5   \n",
       "2     c0df7d49-26f5-451c-b44a-1e0bca60bca5   \n",
       "3     4e5b21c0-e86f-4eac-82b6-1a0d00ae4199   \n",
       "4     4e5b21c0-e86f-4eac-82b6-1a0d00ae4199   \n",
       "...                                    ...   \n",
       "9246  49c03922-c57e-464a-8191-9ebef2615808   \n",
       "9247  2173e6e8-cca6-47c7-8ef6-ea93d3e736f4   \n",
       "9248  2a42d873-b1fe-4256-a488-91db4eaa8d9f   \n",
       "9249  48f237db-e593-4be6-b3f9-10757a1d07ec   \n",
       "9250  190516a0-6ed3-4c42-9f36-dc481a3adb70   \n",
       "\n",
       "                                                                                                                                                                                                                                                                             text  \\\n",
       "0                                                                                                                                                                           \\r\\nn = 1\\r\\nwhile n:\\r\\n    n = int(input())\\r\\n    if n:\\r\\n        print(n+1)\\r\\n        break\\r\\n   \n",
       "1                                                                                                                                                                  \\r\\ncount = 0\\r\\nnum = input()\\r\\nwhile num != '0':\\r\\n    count += 1\\r\\n    num = input()\\r\\nprint(count)\\r\\n   \n",
       "2                                                                                                                             sequence = []\\r\\nwhile True:\\r\\n    num = int(input())\\r\\n    if num == 0:\\r\\n        break\\r\\n    sequence.append(num)\\r\\n\\r\\nprint(len(sequence))   \n",
       "3                                                                                                                                                                  a=[]\\r\\nwhile True:\\r\\n   b=input()\\r\\n   if b=='0':\\r\\n     break\\r\\n   a+=[int(b)]\\r\\nprint(a.count(max(a)))   \n",
       "4     \\r\\nmax_val = float('-inf')\\r\\ncount = 0\\r\\n\\r\\nwhile True:\\r\\n    num = int(input())\\r\\n    if num == 0:\\r\\n        break\\r\\n    if num > max_val:\\r\\n        max_val = num\\r\\n        count = 1\\r\\n    elif num == max_val:\\r\\n        count += 1\\r\\n\\r\\nprint(count)\\r\\n   \n",
       "...                                                                                                                                                                                                                                                                           ...   \n",
       "9246                                                                                                                           a, b, c = map(int, input().split())\\nif c > a and c > b:\\n    print(c //b + 1 + c// a + 1)\\nelif a == b == c:\\n    print(4)\\nelse:\\n    print(2)\\n   \n",
       "9247                                                                                         n,*a=map(int,open(0).read().split())\\na=sorted(a)\\nd=[0]*n\\nd[0]=1e9\\nd[1]=a[1]-a[0]\\nfor i in range(2,n):\\n    d[i]=min(d[i-1]+a[i]-a[i-1],d[i-2]+a[i]-a[i-1])\\nprint(int(d[-1]))\\n   \n",
       "9248                                                                                        n=list(input())\\nd=sorted(list(input()))\\nif max(d)>min(n):\\n    p=-1\\n    for i in range(len(n)):\\n        if n[i]<d[p]:\\n            n[i]=d[p]\\n            p-=1\\nprint(\"\".join(n))   \n",
       "9249                                                                                                                                                                                                                                                     a=int(input())\\nprint(a)   \n",
       "9250                                                                                                                                                                                                                                   a=int(input())\\nb=int(input())\\nprint(a+b)   \n",
       "\n",
       "      generated    id  \n",
       "0             1     1  \n",
       "1             1     2  \n",
       "2             1     3  \n",
       "3             1     4  \n",
       "4             1     5  \n",
       "...         ...   ...  \n",
       "9246          0  9328  \n",
       "9247          0  9329  \n",
       "9248          0  9330  \n",
       "9249          0  9331  \n",
       "9250          0  9332  \n",
       "\n",
       "[9251 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_gen = pd.read_csv(\"../../data/generated/gen_solutions.csv\")\n",
    "df_gen = df_gen[[\"spec\", \"solution\"]]\n",
    "df_gen.columns = [\"task\", \"text\"]\n",
    "df_gen[\"generated\"] = 1\n",
    "df_real = pd.read_csv(\"../../data/db_attempts.csv\")\n",
    "df_real = df_real[[\"task\", \"programText\"]]\n",
    "df_real.columns = [\"task\", \"text\"]\n",
    "df_real[\"generated\"] = 0\n",
    "df = pd.concat([df_gen, df_real], axis=0, ignore_index=True)\n",
    "df = df.dropna(subset=[\"text\"])\n",
    "df[\"text\"] = df[\"text\"].astype(str)\n",
    "df.drop_duplicates()\n",
    "df[\"id\"] = df.index + 1\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7400, 1388, 463)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, val_prep = train_test_split(df, test_size=0.2, stratify=df[\"generated\"])\n",
    "valid_df, test_df = train_test_split(\n",
    "    val_prep, test_size=0.25, stratify=val_prep[\"generated\"]\n",
    ")\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "valid_df = valid_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "len(train_df), len(valid_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/15/2025 22:07:49 - INFO - __main__ - Distributed environment: DistributedType.NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "Mixed precision type: no\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
      "setting seed: 42\n",
      "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n"
     ]
    }
   ],
   "source": [
    "accelerator = Accelerator(\n",
    "    gradient_accumulation_steps=1,\n",
    ")\n",
    "\n",
    "# Make one log on every process with the configuration for debugging.\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "logger.info(accelerator.state, main_process_only=False)\n",
    "\n",
    "\n",
    "def print_line():\n",
    "    prefix, unit, suffix = \"#\", \"~~\", \"#\"\n",
    "    accelerator.print(prefix + unit * 50 + suffix)\n",
    "\n",
    "\n",
    "if accelerator.is_local_main_process:\n",
    "    datasets.utils.logging.set_verbosity_warning()\n",
    "    transformers.utils.logging.set_verbosity_info()\n",
    "else:\n",
    "    datasets.utils.logging.set_verbosity_error()\n",
    "    transformers.utils.logging.set_verbosity_error()\n",
    "\n",
    "# ------- Runtime Configs -----------------------------------------------------------#\n",
    "print_line()\n",
    "accelerator.print(f\"setting seed: {42}\")\n",
    "set_seed(42)\n",
    "\n",
    "if accelerator.is_main_process:\n",
    "    os.makedirs(\"../models/r_ranking\", exist_ok=True)\n",
    "print_line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train data: (7400, 4)\n",
      "                                   task  \\\n",
      "0  85b72f3a-191b-4d99-9207-6a82ed1e73c9   \n",
      "1  008b5cbd-4257-4e11-a061-f19e550b6b3e   \n",
      "2  c9e1ff81-5755-43cb-8439-49ef952f622a   \n",
      "3  c270a9c3-67af-4113-8e7d-a7a94792013d   \n",
      "4  901dd977-9e8b-4b54-9730-6aeaa9d4a9e7   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                             text  \\\n",
      "0                                                                                                                                                      k, n=map(int, input().split())\\na=[int(p) for p in input().split()]\\nS=0\\na[0]-=k\\nif a[0]<0:\\n    a[0]=0\\nfor i in range(1, n):\\n    a[i]+=a[i-1]-k\\n    if a[i]<0:\\n        a[i]=0\\n    S=a[i]\\nprint(S)   \n",
      "1  a, b, c = map(int, input().split())\\nl = True\\nmas = [a, b, c]\\nmas.sort()\\n\\nwhile l:\\n    mrr = 99999999999999999999999999999999999\\n    for i in range(1, len(mas)):\\n        mr = abs(mas[i] - mas[i-1])\\n        if mr < mrr:\\n            mrr = mr\\n        if mr == 0:\\n            l = False\\n    mas.append(mrr)\\n    mas.sort()\\nprint(len(mas) - 3)   \n",
      "2                                                                                                                                                                                                                                                                                a,b=map(int,input().split())\\r\\nif a>b:\\r\\n    print(a)\\r\\nelse:\\r\\n    print(b)   \n",
      "3                                                                                              k = int(input())\\ns = 0\\nfor i in range(k):\\n    n,m = map(int,input().split())\\n    if n > m:\\n        for i in range(1,m):\\n            s+=i\\n        if s<=n:\\n            print('YES')\\n        else:\\n            print('NO')\\n    else:\\n        print('NO')   \n",
      "4                                                                                                                                                                                                                                                                                  \\r\\nangle = int(input())\\r\\nthird_angle = 90 - angle\\r\\nprint(third_angle)\\r\\n   \n",
      "\n",
      "   generated    id  \n",
      "0          0  5998  \n",
      "1          0  5535  \n",
      "2          0  3789  \n",
      "3          0  5950  \n",
      "4          1  2013  \n",
      "shape of validation data: (1388, 4)\n",
      "shape of test data: (463, 4)\n",
      "Prompts: ['85b72f3a-191b-4d99-9207-6a82ed1e73c9', '008b5cbd-4257-4e11-a061-f19e550b6b3e', 'c9e1ff81-5755-43cb-8439-49ef952f622a', 'c270a9c3-67af-4113-8e7d-a7a94792013d', '901dd977-9e8b-4b54-9730-6aeaa9d4a9e7', '7c143f80-2e7e-4890-bee7-ffbdcbf5b05b', '6dcac6bd-9973-47eb-8912-187a2999dc6b', '6d204921-764f-452c-a01d-578e51695a98', 'e51d6308-c0be-44b6-ba3d-c238a0d8e4a1', 'd29dd9ba-3ac3-462f-b2dd-7531b3f01171', '13bcf8ad-b139-4bf6-8b16-b99b7cccf65d', 'f4973e49-2496-4d59-b97a-d64971522a3d', '6671bab8-0e57-4f15-bc39-c933a2495f50', 'a137070a-e421-4d52-9cf8-8a31ac9eb188', '42d47feb-cba9-4d18-8ccc-2c20605db82d', '3c867d85-e9aa-482c-ac5e-574724751b37', '70f7c75a-c93c-48c0-84d1-cf78ed51deea', '0c2c7e3c-f232-46ee-b1a9-748e4ac46772', 'aeb122ea-bb7f-44ee-93c8-65ead3d4f5f3', 'c4a7e827-63de-424a-aec0-aea743d3b5f2', '893cc270-337f-4829-bb45-0f60d1209419', '80f0773c-d8da-4f89-8ff8-f91226bfbbba', 'ce727aeb-b2aa-4da5-be32-636ce90da78c', '5b2cb964-e915-4506-b4fe-22b78644939c', '02324164-09e1-4932-9dec-37eadf4c332d', 'ae532d4a-9564-46c8-a30b-9f1fe7f95bf9', '4f8b54ae-eb36-4c4d-91da-256fc6302b91', '5177ddd2-f17e-4d0a-bf78-21fd90df671f', 'a93745c4-cdf2-422d-86e3-46fc616f4f80', '6f12afe1-01f7-4104-876c-c2eb5123751d', '5895fc4e-b515-464a-a0e2-697d86bf8783', 'e8d630c8-0ae6-4db6-95f1-ded3b8106ef0', 'ef110cdc-5bfe-4426-8a9b-fe4ca7392895', '217c8eed-82ab-4d31-b05a-5743eb20e552', 'aab4a01c-6efb-47a1-8fa2-2ea3e02303c7', 'f9af70f9-5fce-423e-94c5-b6f357e5242c', 'c8153069-3661-4c48-8764-5e3f51309740', '461e80bc-c9f7-403f-9a42-3f1d08a78b1a', 'af37658e-d46e-45db-9ee2-ea44a450db89', 'df2fe73c-bfa4-40e5-b77c-d2ad076197ca', 'ec3cfb4d-5f50-4fa0-8e53-686d10f6c0b2', '11d7d14b-eb4a-4dd7-94c1-67a03264c424', 'daa00bbb-65ee-4c2e-b966-992c51cbdb0f', '1ff5a639-82a9-46d5-99e8-90b0529a5016', 'c6175ed3-a33c-4dbf-8f71-6ef2f9e31411', '9ad8e0ac-34e6-45a9-8f4f-0e8046aec803', 'b316f513-f142-45d3-a702-cc3208e6aa54', 'c1d9340f-9135-4375-a447-490e2e1ff2e6', '83fac1d9-f429-4153-9332-5af26eae0378', '36f03fc0-93a2-4747-b19c-5f77f5ad2aa6', '6824fb27-2339-421d-85db-60758b59cddc', '0423722e-d503-42c8-a744-3bdd6cf13d0a', '853bea78-6aa0-4fcf-8c5a-5f278603c518', '8381a3f6-aaba-448f-b65f-50117785adf7', 'b436a20f-3378-407b-9d0c-adf4962d847a', '3bda5701-c742-4f44-9bdb-d4b772de2705', '027966cc-bba6-4e6a-83bf-ea3f730fb59d', 'f7c03795-0238-4dc2-a83e-5674ef35ad88', '2a42d873-b1fe-4256-a488-91db4eaa8d9f', '3876c09d-7f12-4c69-ac5c-8ca780dcd633', '0f42de72-e8d1-4f41-8797-90a6cd184af9', '5ad50653-d34b-4238-aced-8ed04eea645b', '43690a23-0ff2-4f9b-8410-ec7917ae05e3', 'cfc0314d-ea18-49f5-8b83-e12b2cfae492', '06c76227-d39e-4bac-8f71-f68c262dd42e', 'f219f00f-7aa0-4548-9766-13c878269d42', 'ac08298f-25c3-4193-9ae8-4fdb89da54e8', '4495049c-7679-4fd3-804c-70c67ad5a1dc', '5eebb219-dec9-41ce-83c6-efc4a4670acc', '15a679fe-9f02-44a5-8720-d22dbf7b05ce', '4659a273-9c89-4ff8-a1bd-6d0ae87e9915', '91935175-de25-4b6f-bbaf-d836a8e01406', '5986f14f-59c5-428e-84aa-553175c8bdb9', '3d109570-fadd-47bd-b0cb-2d9d34ba11ca', '33eb8e68-cf75-4892-b87b-97ceeee27d04', '9e51c02d-991b-4cb5-9ba1-5709d2ade797', '1c260f00-9384-4b40-8fd8-64c4ae771acb', '13f523e4-1cd2-4724-8b60-a0f6f25007d9', 'dea8d696-205a-4637-aa51-cf7d02c29a02', '9e91eca3-2074-49fc-a46e-35630d7d0e53', '4d25e12d-091c-4350-a744-93b5301dbe02', '180b3b37-5ed9-4f3c-9300-48ae0b5121fa', '44c593b7-23d8-44af-b1aa-6e5ecbdf6cf1', '3d7a3219-e451-4f8b-894c-c96623eba5e5', 'fa181552-a073-4c25-928c-1a5c48505a6b', '51da05db-a06f-4b98-98be-db263befcf2e', '2b7b67a2-81d6-40d7-b1bb-aa032863511f', '0024e95a-bf71-4dac-a246-626b5821e403', 'e5e8f4d5-0b0f-4a52-b5a7-12f8ef0a52f0', 'a4b90367-4dc9-4d5f-84d6-56245ea5afc4', 'd0c2eebb-d0a4-4fc8-9a98-9d5781c4d2d7', 'fe35f9e7-0b58-461f-9278-39f03054e886', 'a4accdf7-f726-49d2-b19a-aeb590224402', 'a11ad4e0-abf7-4110-9d03-04d451d484df', '87b17251-9fef-4c2f-9cd4-79662ec2957e', 'a62a737e-0fbc-451b-9f67-2d7804740ccf', '7ccc54dd-0df1-4cd5-88eb-63b0a869cc01', 'bd77bd8e-1bf2-4a3b-b674-9eddb5375116', '4cadd9be-89f5-4d54-b38d-f823b7087153', '8c60181e-f560-4f27-a609-9ab45077ce53', '8ce41d60-130a-4863-a45a-1fd4e48e5f32', 'f6186143-1fb6-411f-a770-fda693e2e9b8', 'd10ce529-697f-4d23-8c67-948d245c3668', 'abd77e3f-81bd-4c24-afdb-b64873f7c1c3', '35bc693b-1917-49ae-ad4d-bed0d5a22583', '3d13981c-49a5-449f-aef6-a62cad45d8f4', '84b45b43-cc73-4b14-ab6e-8b970134fb03', '28b5bd1f-2393-42f8-a320-976b5072a75b', 'a40047cc-77a1-4a37-9e28-a61947b07df8', 'fb76df8b-f50e-400b-aa83-29cd6b682372', 'cd337303-7592-429e-a0b0-a9882d16ca3b', '17c6577a-b831-485d-ba22-fb47923019b4', '4c960d61-0634-4b66-90e7-3bf2894ef6de', 'db113d71-211d-446c-8cc7-3fa4c4772bf5', 'c0df7d49-26f5-451c-b44a-1e0bca60bca5', 'd424177b-fd38-42f2-871e-63244e1e7a08', '17723461-2b83-4281-926d-4d9255518c42', '1b2dfff2-077c-4804-9067-dec63bee6584', 'ae521e91-eb31-4263-8069-60d54d9783e6', '4a5ca4da-8ce7-4613-b0d6-23c6ebb491ed', '3d57ecc4-72d1-43f5-ae17-2cc26c570f11', 'a0497858-245b-4fc6-9d58-990c5e2f0724', 'e77e3519-0023-4628-97b4-562a17add717', '09dc2eb4-f9d0-445c-aa81-994928c2d4b8', '1b7a231c-acf2-4c20-87f1-8615e27d21df', '5be45c97-769f-45be-9ed4-b4dd633ac057', 'bb52cce8-05b9-4e42-ad95-7b5f4e435d31', 'b9308722-8825-4c03-a04b-0e20c61a977c', 'abbcc924-83f6-4516-b276-427d9cbe00e1', 'd0e35e20-e37a-4750-8c0b-7641a3b72277', '35d772a5-7770-4a91-9118-ad11e4ae7feb', '1d7d28c9-4d1b-4d70-b2e1-b0393775ab4a', '48f237db-e593-4be6-b3f9-10757a1d07ec', '8b0d3d79-b497-4ccb-8f9b-4b426af3908b', 'db1817f8-e2ae-4d2b-8481-53c70ddc5661', '2173e6e8-cca6-47c7-8ef6-ea93d3e736f4', '48531b77-6537-4389-a998-5c74e35ac9af', 'eabdf11f-d1f1-44e0-8017-20e8e541ec68', '510dc5c7-a46e-4b15-be50-4ecfa1e046bd', 'ffc65b57-d995-421d-a0bd-b34cc8cf34a5', '704fe53c-bcb7-48de-a964-e687a0ae281c', '4c5a1413-e27d-4b6a-b218-bc8e2a3ade0e', 'b48599d5-44a6-4b34-9cdf-8ec2d44054d6', '8cb56479-bd55-4e5f-9901-b60fcd56d77f', '770952ee-5595-4690-9f1a-a172955624fa', '94ac4455-5ad7-46a1-835a-ac155d995664', '7330236e-4855-4be2-bef9-6e6766bbd181', 'a62dd931-540a-4081-bc01-26a8e58aced3', 'ea085abc-b6a7-4545-86cb-85395a6c5937', '3ac18983-f406-44b5-96bf-2aa5ce5a6c3d', '9f7a68f4-0125-4e43-a65d-6c66ee1629ec', '1d86615d-36be-40a7-9d08-193f1af8b6b8', 'ba789162-5596-4059-9f45-f6dd0f6f65e5', '7d8fcbed-1f16-4d19-8a17-6560267bc64c', '5773ddc5-745f-44f7-aab7-59268bb9c5cd', '4b28d852-6b47-4db4-aa6b-099ecb0e7a8b', 'b85b4d55-02c5-4f5b-9c58-538068bf5699', '52fd296b-798f-4462-889c-5b49172bf987', '36d58b20-7fe1-452b-ac10-e1ed680aa6b3', 'bcf28659-36f2-4add-99d1-7b600b104c71', '9844781d-49b1-46ec-97c8-257016eb564a', '614009a0-821e-497b-9a0b-07c0dbe033b8', '08f18ec8-c939-44c6-b125-642f6a2341fa', 'e403def2-7943-4432-b5dc-a6073bf62a9b', '872b3f76-e52e-466c-88f4-e5cd230f3fac', '0cc13605-3cb0-48e8-a8d7-10d2e1b77520', '702fc37e-8257-458c-aedd-8ca35534289a', 'b8f9bbc2-7933-426f-a21d-ff3e82abc198', 'bb8bf498-d02f-48f2-a15a-f8cc813a5c5f', '19c885d8-a7aa-480c-946b-9742a59e1d41', '267f2223-0096-4b57-bc54-1c2372772391', 'b117fd99-a7cc-4e2d-b791-3827947a68ea', '184def68-8d78-42ae-b39c-3ed0566d685c', '6011a409-d175-408d-9ca0-dc10948c2f69', '11f5282e-266d-41b6-b87e-01642625b2bd', '4e22855c-d210-4e19-8715-87f6cf4bba7c', 'c2081cad-a682-43e2-8960-081ef8963a37', 'e5673478-3dd1-49d0-b1ca-49dfa6304570', '836710cd-fa04-4afc-9ed7-2652ed8894a3', '66c9f51f-8598-480d-85ef-3830594163ab', '4b1be5b6-131a-4853-bf20-dadf3bbd10d9', '521b1be0-3bd5-45f4-94f5-dad4b82ad375', 'd949e12a-1807-4b82-a4ab-c1a178a79888', '0ef5465b-370a-4084-bd37-fb4d3b6b398a', 'de810164-5bf4-4c23-ad28-410552b3d77c', '49c03922-c57e-464a-8191-9ebef2615808', '311d9bb7-84d8-4a04-9af9-fba11c6f224b', '7aecb159-d960-48fa-8ebb-1bfa26b302d4', 'e538d2d1-111d-4904-9de6-f691cdc9fb50', '96848df3-0772-4855-bf4c-6fe2a471754f', 'cfed631e-c3d2-495b-96a0-5c89a5a8aee0', 'b93c1e57-b459-4cb9-b55c-c7e9572a4185', '408e0ac8-b3c0-4123-bcb2-e396802f5399', 'a34bd4d0-cc64-4d5c-ac41-7578aa90494e', 'c5c3180e-2ab6-42fd-b993-af221e0070ca', '2488a6a1-fc84-46c8-bd28-ea8791f78298', '875ec0a5-0a8e-468b-b0f0-1b32c0337354', '40d4963a-6b16-46b1-850f-ec5a885e4f78', '94224cd9-666a-4814-8edb-60beb14ea59a', '1b689872-4b61-4615-a14e-24e7a0bcb1ba', 'b962261e-7638-421f-9ea1-ecd77520e209', '0c04c2f7-1548-4fa7-afc6-5ef064ea3a9f', '645dbba8-e48e-4111-abe4-d1ca480792d6', '4bdb3c96-f95d-44f9-829c-cc85cac5ea72', 'ade9b273-aad8-49ba-b6a7-7ffcb02b0011', '663bdee2-c316-4349-847d-5df934d638c4', '79312fbf-4cd4-4453-989e-43f3cae93d51', '413c96c5-232e-4eff-9ba1-b774170c53c5', '84118453-37c4-4256-a8f0-5dc2707d4e35', '1877a515-ff97-43f2-8362-bc2952a26b5e', '399c561c-44d6-415d-8c3b-3e83018f5f2a', '2373f3eb-bf38-46fd-ba92-ede0c1bc0ac0', '4b81460a-5cad-47e0-b9ab-83fcd6a089ea', '431be734-39e6-4f58-aec7-61e67c8ee1b5', '6b40330c-4690-4ef2-9bff-4d20ab893a48', 'ebc1af65-7f28-4308-a3c3-07335f379d84', '39674b7f-1b5d-40b8-aa5c-02f2ac4a2a4b', '46191358-5b90-4de8-b69e-0b3597953584', '8db514ad-0242-48a9-ab6e-85b0e8171d87', 'c479ed62-3a40-4f93-89c8-b674826ab144', '4ecec1ec-211d-4ce0-bd4b-ee2498ae1afa', 'e16baab9-5d32-479d-877e-04518a247380', 'c4ced8e6-dec6-4f4a-8a79-f5800795a08b', '6bd877c6-1740-408f-a6ca-2f8adeae08f5', 'cc10dddd-3324-493a-b0ac-ec2ff8c66cf6', '15f19bc8-7be3-4a44-a7b1-fc7505badaed', '7da74132-0efc-4c1f-9755-f247bbba2ab9', 'e1980664-e539-436e-af4e-1dc094d9908f', '5362054a-bc83-4623-867a-66a72e38b366', '6bda3287-a2ae-483d-9171-8373a20531d9', 'ba76fdac-e782-449b-91a3-c05bce9c93bd', '5ae76e60-094f-4777-acc2-83ebca17f84c', '27e3a45a-87d9-4afd-8f88-c8b783da4dcf', '6d14c7f2-95e1-464c-a3cb-bcab860928ae', '2924cfce-8ebf-4fe5-aa8e-046256297fb1', '09441e0b-3a6a-4c17-a1e3-6bec7305e997', 'bbb640ed-435c-4dc9-8625-87b81a5a9b22', 'ddff994a-fbde-4c58-a91b-9e3a3872e088', '5d02ab7a-4394-4098-9f7a-ed3912083888', '1187526d-8b3a-4a9b-8098-bbbf8d9d1423', '3316f095-b094-488f-acf6-0f4b7cb39d3b', '3afc315a-4d55-4193-8135-d8dd5c533c49', '87ecc56e-ce90-4408-bb34-25f0c2a959f7', '190516a0-6ed3-4c42-9f36-dc481a3adb70', '98a85385-25d4-44f3-bee2-2b91da43daf0', '1a0c244f-dc1f-4d44-8d80-19db61bd9e0c', 'd49e80f4-ce33-4ded-aa53-337f8d0f73b8', '787d2a09-3617-4050-820e-a01d43b2b188', '5e7b7702-01f1-4717-a1b4-0cd9af8cabdd', 'e291f79e-b00b-4223-8250-eb7e45d39e54', '15ca1e03-d60e-41ae-bf1a-b902059fb037', '9428daf6-0093-444b-a8fb-cef9003392e2', '03a8a5e2-f2b8-4e7d-b0ec-acf8aaa72e29', '65a82391-b543-4715-91f5-4c5e7baf3fa0', 'ccfb8d38-8277-4806-ad02-80a6b6aea9cc', 'a9c318ef-80f1-491d-ab11-68ce1859b858', '9e9de547-58f5-45b9-a733-37cc732bf237', '01c8944f-0a22-4bc7-8338-acd655974e1a', '420a5758-8cb1-445d-9bf7-bd8017a41cb2', '1dfaf2a6-3a2f-4c32-b6a3-f6a752d20be4', '177f714d-8f2d-4630-8a45-86b5a1799099', '931dc9d6-3183-4d35-bee6-95b210e0268a', '06a06b1c-da2e-4210-b889-371de309b82f', 'b4e8d0e8-b2b3-4675-a090-16c08e1e936c', '06d7584b-69d4-4bbe-b919-2cee80f53cae', '2d45afbd-a12c-4de6-8b7e-13c61a6400bd', 'd45974a2-6e4d-4a5b-a7d1-cf456bf9e2e1', 'b24bd86e-4963-406a-8eb5-fd3ad60e6bc1', '443dff94-1bdb-4880-8ae7-7a899a197e4e', 'cf10d30e-74e0-4d68-b804-84b51b2900e3', '5b6da202-e075-48fb-a015-421187973431', '777756d6-d867-4cc7-978e-717933384418', 'd5e4d47f-6494-4c3f-b408-6562c81ae4e7', 'eb763311-8a08-4e91-a8d1-33a228a1f3f9', '6c718c88-bb90-4a37-ae7c-908916a5957e', '95831070-88fb-406f-8997-c0fc4027d623', '43c6f24d-b89c-4762-9dc6-b6c3aaee6f1a', '15420900-ca97-49e3-846a-13bd92d9bace', 'dfcd4c48-6f3f-4a53-a03f-e5abebfebdae', 'cfe47bb0-2389-4fae-84c2-9287605fc571', 'efe1a482-a2db-4971-a769-8b60a0beaf64', '66fe36a2-dbeb-4e74-b4cb-c2279ce0b3a1', 'eab227d7-e139-4289-8d39-eaa2b5b376c0', '598ac092-b788-4134-867c-8e307d515e67', '076a1e7a-9e4f-40ff-a271-7a009406d02d', '0718b9a2-e909-4d51-9f4a-a1de2c698eb1', '7762ce71-62d8-4d9a-b192-d363f5ffc725', '6749cc47-75b3-4622-915b-5601e3963b66', 'd48be896-b484-440a-9ca5-2cc0f31533dc', 'efada5f3-2c43-44fd-8907-f15b1cffa135', '75410156-cdea-4efc-a0d6-91e02bf38e32', 'dffaaaaf-3e46-49f2-b606-2769c2dd0bb6', '0e068baa-ec82-4085-84a0-c436b5832755', '56188e25-bcd8-4838-a078-f9da9fa73c8b', 'bb650c26-e5ff-4faf-9447-76e7e6965b4d', 'e9f3df82-446a-424e-a07b-3c77daa739f2', '48521f16-2133-47f1-b071-0706a6062411', '132b4d29-b1fe-4591-be7e-9e4e150e35b6', '58443c34-5e1c-4cd5-b526-6442bc1c012d', 'dd32efc4-7f8d-4180-b85e-a2c76a64a9f3', '6ea3787d-36b6-4143-a884-60b71510c4dc', '0dca2e13-f1bc-4578-8818-48b97c2d7490', '1a27e016-52ff-4e78-89cb-956f0a7cac6b', 'e9f94ed1-8675-46d2-95fc-4dfc33c41c2b', 'f09f326d-8329-4d39-b628-04a1b3d99f07', '3276b711-2292-488f-9353-be7b86ab5e1a', '076cbcbd-ca30-415b-b2b9-701ea29eb934', '9acc7b61-f8ac-4953-8b12-651c2d7f8d48', '71b7440c-fd34-4967-9b28-783a9aa1b104', '8aba26dc-aa58-4010-8c1a-81e0ce626bae', '49d32baa-e711-42ee-91cf-836c86d0d699', 'bfa57871-3996-4c10-b9f9-fcb21a8e6518', '4769a9c2-112a-4210-bc3f-ca1162d376ea', '33cf3c19-292d-4544-a9a5-0e2a3c965272', 'dc2ce7e3-6bb9-4308-8c20-15410d948a3c', '803f2a75-a4cc-43e8-99a5-48ed1a684aa1', '6381eb46-a216-455c-ab82-3b703f2da42a', '0df7e1f2-c1c4-41f3-9904-a9e4495a5bfc', 'e0bc4009-5913-49cc-96c5-a8c4988f9103', 'e02095cd-3f62-4005-a067-a9da53d342bb', '84cf2736-6f23-4127-9ed9-7027b8fdb369', 'cdd79a46-8605-41d1-a344-70e7c6a9b8c2', '70c96088-3bf6-4189-985e-a2d564337989', '8b57cf61-951d-4c47-b41c-90e13b9f5358', 'ce6090fa-0f91-4cc7-887b-f2228001b1e9', '13f1bd7b-dd8d-410f-968b-c1be930de69c', 'a0f460df-bf11-47a1-b164-d95c2d265cc6', 'f9f08d20-e4e6-49ac-8682-f4b7100928a4', 'c519c7c3-cc1b-42eb-ae0d-77219a6ca340', 'b8468aa3-8577-4202-9b73-f9e4c346f7bd', '26acdc8d-1ff5-439b-81bd-00672786ec6d', '02bc07a3-d63a-4896-b585-e74c06bfc7f2', '8adf2876-9ffe-4037-95a0-5207cd96e42d', 'f56de6b0-e5eb-4ffb-b0c1-1e471b7f0b35', '540d34fd-8182-42ac-91f4-8951c353f470', 'db8534b0-ffa9-4c1b-9d86-4797814b3074', 'b1cc81ce-a1cb-4d57-9438-fb792a698d9b', '6b1e0963-bf0b-405e-b555-435a6225619c', '16305713-d2dc-4ab1-8bbd-107594c55519', '4e5b21c0-e86f-4eac-82b6-1a0d00ae4199', 'de8af9ab-6f54-4cfb-a99f-3c734f989615', '8e83aa88-b80e-4a89-97a6-773e94a0acf3', '2335ee80-a2b1-4e2b-93c1-b3bc7d2720e8', '430aade4-55bd-42b3-9586-1389412540a7', '7805fe34-1d52-43d6-8d18-16d0fccb4c8c', '6cef62b6-dffa-42fb-95a0-17f9f2b300c2', 'd658f071-1e55-45e3-b3ad-e9384d03b9b9', '24dcfdab-f852-4c60-b195-edf3b81c45e0', '71fdbf7e-8eb6-42ec-8fd1-6d792ca9202d', 'bcf4caae-6f1c-488c-9cab-bf7232dd9614', 'ead36ff4-8cf1-4c6c-8a43-ab69f623fde7', 'cb96b982-37a0-487b-8b5c-67d27e6f7094', '5d367d53-2714-49cb-b00d-72626739e49c', 'dd42948f-07fd-4e99-98e0-2696850335fe', '04dd6eca-f83b-4028-a21a-4e09c9333c0a', '445c41c2-fb30-463d-a133-ea25ee4f72ad', '1c8423df-d978-4e69-b8d5-886b1c2c745b', 'addeb428-01ba-4987-9b50-6ad4f8c62a74', '2fbbe9c8-9707-450c-82c7-1239bb38b1cd', '413dddee-a132-48a9-9753-e5bef469b529', '7488edcd-5001-458e-955c-d220494cffde', '1ef1f261-55cb-46d2-a802-e3c83ec23c72', '82981a21-b600-4423-8f6a-4857c49e78af', 'c0632a37-be24-4c63-96eb-d2a1da7f48e6', '091ddb60-bc05-4be5-808d-ce061c459e3e', '19b7ecee-e69a-4f88-bc8f-07a8231ffc88', '4d88fcc7-08f9-47c3-86d4-9f59b6f127fa', 'ea8b8ea8-d5fb-454c-ae09-380e26090353', 'd545163d-9cf7-4877-9ec9-53b8c4b1b499', '54c95a3e-10bc-4388-9722-619f9c35563c', '6723979a-b30c-4944-b9fd-970aabedbea3', '22e720bb-1b6c-470d-bb7b-da0de5a83f45', 'a809c102-e8a6-45ff-9baa-9a998d1927f1', 'bc87b483-769e-4df9-9463-bae5df9fb96f', '2ee76cc8-f815-4807-a797-4059ae8a8d76', '83c25cac-cf59-44a9-9214-be35c0bd5e06', '419d664d-81aa-4201-abc6-d514e7ee1691', '63fff392-7a26-4842-8308-8e12386127ed', '40f61f4c-c5c5-4f34-89bf-f0ca312a3c75', '5d8eca27-fdd6-446c-82f2-5e3207d3b0e8', '66cdaa4c-6fe2-43ac-9cc8-08f59916608f', '150821fb-095d-4519-b21f-2462c0415618', '74a21b08-f61e-495f-a883-f02328dc4dae', 'a7278e0b-c30c-439a-94ba-68a803df68b9', 'de60668c-9cf3-4d87-80d1-457552bd8a37', '5fc63383-931c-46cc-a7d1-308dc271fda6', '2166392b-950d-4f7b-8b28-ecb72204576d', 'cb0bfea6-3e23-49c9-b5f6-bec9789f82ce', '80cacb8a-a6c2-4757-9646-317c1594c18e', 'e89d534d-5861-4b7b-b06d-d37e247dc249', '8dc31c6f-539a-43b4-bf20-f1ffeb429b68', '170140b8-81fd-4d56-9f3e-471b54fd0757', 'f611255f-9f87-4db6-b36d-596aaa95886b', '7c335c85-1302-4b0c-93b3-e9e2d73a2a28', '3e320d9a-cc8f-4ee0-867c-a570153011f6', '82028d7b-804a-4c3d-acf8-29bc892147e5', '02fbb42a-472d-4e95-a306-13c6db519654', '94a4304c-1628-4b48-a1bb-62970467c416', '53c6ed65-d137-4acc-97ec-8200a4ee1eb6', '85b0ee0e-7ee4-4014-9cac-8d39ec3963e2', '75214b1c-bb28-44e5-8474-ac6b45c80db9', '02483234-a45b-4799-a9dd-04494a21998a', 'd0a972df-02e0-41b9-a5e6-ff41f6ccc00e', 'f2fd916a-4061-4f42-aa02-2ae337339c7a', '5bab2114-725a-4548-aa0e-c6b7296898d5', '40d78243-79a0-4ec7-8ff5-47f803a55e0b', '18bbabdd-799e-47e6-b085-3698d76792e0', '8698fe10-a13a-4451-88c5-948392ab0423', '825a391d-5fcd-40a6-8a12-bdcc3dc9622c', '94c2e814-50e3-4d66-a2b1-fa52ccfc19ef', 'c96e0173-605e-46ae-98b6-d1df2bce3269', '9cb9b7da-39db-403e-8612-483ae6cb4067', '820cd949-bd66-44d2-82e0-bfd517584c5c', 'b4962d04-c827-4a5e-8a7f-c749d635df29', '9ca6957f-6cac-4516-bd98-d6ab2582b5ba', '3128bb96-33e2-4b01-b4a0-f067a421045c', 'aea68e26-3891-4316-b0ca-0091e0125d96', '7615eb4d-49ce-4586-825b-56ea69f157b5', '640ca41d-af9c-452e-93aa-45d95f4daeee', 'f2d92959-39d9-49fe-a9b1-5868567eeedf', 'ab48f655-0a9b-4b20-8bbe-fd806719bb53', '39cd4d3c-2ead-4da6-a322-b3be4be280c7', 'ba55d077-468c-489c-833a-84b7049e1458', '1b52e7f3-35b9-4637-9769-0ac2a25d7799', '0e835939-e24c-4e99-b563-d8be842cec4d', 'da09ebe7-a076-496e-a98b-783c7c59eabc', 'b8c265d0-999d-49e2-a5fd-eed95708bf97', '9095afd4-9e40-4925-89d0-90b1f67e8e0e', '050f0a60-1200-4dec-acb5-12c3b9f24d0d', 'c0ed6e9b-f602-4b3b-8aef-52dbb2485110', '5649f199-b867-4d54-aae7-95a54f034bf5', '86c5916f-839d-4d9b-b608-2c25b2a5d6f3', '3abda59e-f14c-4509-8c89-fa074d981177', 'f2aee372-d88a-497b-a1d2-64b122fc8b0a', 'f6f2af27-2624-4cd5-8ebf-27aa0c54e92c', '31c3dbe2-53d4-4355-a73f-50d94fe0dd67', 'a1653f16-6401-480c-9131-9fef0db152a8', '7402f10b-561e-4547-8f06-38f69d85a6c9', 'dc87e1dc-871d-4d96-9273-255c1c5db049', 'ac6535b5-675c-452f-b494-e04adb74dbac', '2a29bf6c-714e-4d56-83a8-0120f9ce6f9b', '58ca4991-edd2-4ea2-b81d-d9a258740ded', 'e618611f-e3b1-4f6f-a57c-44f0d96e4184', '93bcd112-f941-49df-8fc8-d8323cea9612', '7aef5f21-3d8a-4711-9507-28bcb1b28522', '0f1f3e41-5da5-4608-b937-2475432abe15', 'afdf5a16-8bd4-4b26-a202-608e047fb891', '44a9a266-a3fa-442d-9ab4-bcc8a921f296', 'c7512b39-389d-4ddb-b3fe-5475bd01a088', 'e8cf929e-fd4d-415a-b28b-df10c5475b9f', 'a54311d1-e202-4723-9adf-3b698d39ad41', '945dd62f-c5a3-4a5c-888f-d188a7c8cac3', 'a8e815b1-acf9-4281-ab55-793e1595c689', '02f9fab5-9fec-4436-b553-57902fc3ce32', 'c0fb5634-ca08-405e-bc61-ac50fc7d0a99', '19e69528-b684-4f78-875e-983ae9e44f70', '9172a178-48dc-45ac-8c7f-fb00742ad80f', '6f1e85b2-e2f0-4610-b359-275ba6b71bc4', '004dd7ed-c513-4c47-9a8e-76828ba86070', '6c2adae3-f5f9-4088-9bc6-567fe66476fb', '157c7563-5b83-4f84-b184-e15788a65471', '9cf4d5af-4fda-4443-9613-82dff00ab963', '6f681490-aad8-4402-800a-db3570a52a8e', 'cac27472-4c12-422a-a596-3332c232da38', 'dec8fd85-480c-4c32-8a7f-8fda025a778f', 'f7c30e56-6dd9-43a9-86d3-456364c5c78a', 'ba19f22d-c2e8-4297-a112-1bd049ae9bdc', '982ed021-8351-4afe-9d79-111527937b47', '813ed199-bd60-41e2-8096-500a414b3c9d', '27b539b9-a075-4402-a90c-863e1b839e6c', '11fefb8b-3765-4524-96f6-c63e9c6e6a36', '7c31dab6-5b9e-413f-94fb-2f42e652f8e4', '6d5943fe-80bb-4799-adf9-505069a003c1', '0cc69b6a-3909-441a-a329-8b2c81413bb0', 'dc7df795-44d0-4efc-a04b-f0701610200f', 'd752e481-f9e0-4d06-8ad4-ca4b16a1195f', 'd0bda657-ffb6-4ebf-b518-46e59186d308', '1038fcef-65cc-4f6b-bde1-5d7d3bffea34', '602eb499-46f9-4cd2-aaf8-0046ab7077eb', '20988eee-e004-450f-8f0e-a201504e15b2', '56e6efc2-5078-4bbf-852e-4042cb80c663', '33a72323-4374-42f2-8f8b-28a1ec69a960', '475d017d-07d6-4a0d-b666-82de261f4e17', '9f26801e-6448-47ab-af7c-8cd9ec482ddf', '964962f4-923d-476e-b370-36324b1dd5d3', '6a5a3a27-897e-4d43-8eba-5774b08efba5', '7f4176cf-336a-4612-9d4d-31057447b99e', '94581bd4-2060-44f1-ad09-4c18917d4f17', '3c3ef2a2-f6fa-4cc9-bd4f-fd1bf5a07ba3', '9e28f52f-22bd-4f1d-88b5-cff58644e932', '3ae56164-1134-42f9-8fd7-204a82b81e52', '425c8750-0bca-407c-b56d-35178e64f878', '34353951-c305-4bd0-ac17-9df1578bc183', 'f2fd7d1f-60d9-4447-8775-ae1cb1500275', '5f3269b9-ef62-40cd-accf-5dbce420975b', '3667758b-e19a-4799-934b-a51dda7dfe40', '8f601481-e94b-4fb5-bd98-938b284df9fe', '86e003c3-5c8d-4897-9f9e-a17c896cc8f1', 'd7e24cdf-a14d-405b-b6a2-94acc8731072', '150f8ae8-1577-4cb8-98b7-775b5ddba6c1', '916cd758-8a73-4909-9ac8-2f0d57f29095', '993d5917-3656-42be-87ec-bbde4aff5607', '8197a3b2-3c8b-4da4-85c2-8afd3c9c9e3e', '26d1c993-2e68-4018-bcaa-9bc3b167e183', '31e85273-27d5-4648-8ff3-298be60d690e', 'dac9c476-636f-4d94-b428-2eacbaa8556a', '6979410b-f2cb-41d6-8e3b-dabf463e683b', '0d9002cd-2fbd-461d-8c43-ba0350fe2e8e', '20829eaa-7182-4890-8b7e-ec2f50debde8', 'b37c6232-1a19-47d7-9250-7e111725e611', '5139f663-9fc0-45bd-af9f-53b1095bbd7d', 'f1251ef6-f02e-4035-8703-80c1224be624', '33211b17-8264-45f5-b080-9ef68ce82655', '95d48130-7035-43d4-ae28-e60b98e3b8c3', '8b665b81-e179-4da1-8582-bdd334355d33', '519d49f4-2044-4bec-8164-97ef458dc2c8', 'f85752e7-1961-455b-a754-22558c602c86', '3a5391b3-7918-4fa8-9eb6-8478632f15f0', '1516a6df-2eca-4d9d-8705-395d2d5f3a1d', '6b8c932c-83a8-48ca-a113-6d30c2614e04', '580154b5-aff6-4be5-aee1-ef65fd358eee', 'c0e7c591-cf6d-49a7-898f-50c883fe3707', '58d6743b-8cff-47a7-bd29-e0ba865928f3', '7880445a-3568-4939-8f55-d80530b696c0', '64f2a270-a305-4e63-82dc-84c798e2078b', 'bb43cfa0-0a74-480c-a052-62bd7875a4ec', 'bec8ed8e-a7fa-4cf9-a000-4b52d98ef48e', 'b76c8f23-a934-45a5-ad8c-8396fe67301c', '41dc3f51-3de3-4b99-8c8f-911409a91ad9', 'af34735a-a422-4900-a41c-ce3188000595', '64651a5b-ea7b-4ba7-935a-9e1f4d550db9', '2289a224-3dec-40f4-935f-a614d8469cf0', '6ece3435-75b0-481a-bcb8-5b5e036fcfaa', '65a88d3c-866e-447a-b7d0-85f05c4c6441', '606ade49-bac9-436a-ab0f-9db356c7a1dd', '4849bab6-fd74-47ab-b036-ee7436a155ab', '1384b216-a7b8-4150-a30c-9d502927d121', 'ae73b48e-98a5-492c-8872-f60c90a3ff1c', 'bee15a15-bd8c-4a01-911e-ddf3e5ba6f80', '8bd559bb-2d0f-401e-96cd-b7aad95a8365', '05c50d73-fe75-4975-9d19-7e26e8c8d05f', 'b0ef8ffa-6aa7-4ef4-950b-f26dd9b3ae41', '71b2758a-6863-4cfd-b6f6-88ebb73fb83f', 'bcc460f7-6c44-405b-a9c6-b884f3e1d171', '13be4a8c-6e1a-4e47-9bb4-4718777ae867', 'd8d82938-fcc5-4c3d-9b25-e5b23632cae0', '4e146a7f-e7ea-468d-8ff3-bc5bc504e0bd', '7c60a259-3411-4f01-a186-98993f455e20', 'd1cb74c3-9d35-4e77-99a3-5ead49cbf6ee', '765e7876-1539-4ec9-a84e-dcfb4da2e20b', 'a6dac91d-dc25-4a4c-8045-f2477dff47f7', '6aae7e54-46ae-4139-acfe-077fa3532601', 'ef273600-92cf-4397-843c-ed406d948390']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kiaver\\PycharmProjects\\ml-s25\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Kiaver\\.cache\\huggingface\\hub\\models--microsoft--deberta-v3-xsmall. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "loading file spm.model from cache at C:\\Users\\Kiaver\\.cache\\huggingface\\hub\\models--microsoft--deberta-v3-xsmall\\snapshots\\4b419818330868dff6a60ad3e6b1c730f8b8c0c6\\spm.model\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\Kiaver\\.cache\\huggingface\\hub\\models--microsoft--deberta-v3-xsmall\\snapshots\\4b419818330868dff6a60ad3e6b1c730f8b8c0c6\\tokenizer_config.json\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file chat_template.jinja from cache at None\n",
      "loading configuration file config.json from cache at C:\\Users\\Kiaver\\.cache\\huggingface\\hub\\models--microsoft--deberta-v3-xsmall\\snapshots\\4b419818330868dff6a60ad3e6b1c730f8b8c0c6\\config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 384,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1536,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"legacy\": true,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 6,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 384,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.51.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "Map: 100%|██████████| 7400/7400 [00:01<00:00, 6550.41 examples/s]\n",
      "Map: 100%|██████████| 7400/7400 [00:00<00:00, 31489.15 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column name ['__index_level_0__'] not in the dataset. Current columns in the dataset: ['task', 'text', 'generated', 'id', 'input_ids', 'attention_mask', 'input_length']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1388/1388 [00:00<00:00, 6940.00 examples/s]\n",
      "Map: 100%|██████████| 1388/1388 [00:00<00:00, 33047.95 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column name ['__index_level_0__'] not in the dataset. Current columns in the dataset: ['task', 'text', 'generated', 'id', 'input_ids', 'attention_mask', 'input_length']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 463/463 [00:00<00:00, 6173.39 examples/s]\n",
      "Map: 100%|██████████| 463/463 [00:00<00:00, 28941.32 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column name ['__index_level_0__'] not in the dataset. Current columns in the dataset: ['task', 'text', 'generated', 'id', 'input_ids', 'attention_mask', 'input_length']\n",
      "================================================================================\n",
      "setting random seed in data collator as: 1744744105067\n",
      "================================================================================\n",
      "data preparation done...\n",
      "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_ids = train_df[\"task\"].unique().tolist()\n",
    "gdf = train_df.groupby(\"task\")[\"id\"].apply(list).reset_index()\n",
    "prompt2ids = dict(zip(gdf[\"task\"], gdf[\"id\"]))\n",
    "\n",
    "accelerator.print(f\"shape of train data: {train_df.shape}\")\n",
    "accelerator.print(f\"{train_df.head()}\")\n",
    "accelerator.print(f\"shape of validation data: {valid_df.shape}\")\n",
    "accelerator.print(f\"shape of test data: {test_df.shape}\")\n",
    "accelerator.print(f\"Prompts: {prompt_ids}\")\n",
    "\n",
    "with accelerator.main_process_first():\n",
    "    dataset_creator = AiDataset()\n",
    "\n",
    "    train_ds = dataset_creator.get_dataset(train_df)\n",
    "    valid_ds = dataset_creator.get_dataset(valid_df)\n",
    "    test_ds = dataset_creator.get_dataset(test_df)\n",
    "\n",
    "tokenizer = dataset_creator.tokenizer\n",
    "\n",
    "# ------- data loaders ----------------------------------------------------------------#\n",
    "train_ds.set_format(type=None, columns=[\"id\", \"input_ids\", \"attention_mask\", \"generated\"])\n",
    "\n",
    "# sort valid dataset for faster evaluation\n",
    "valid_ds = valid_ds.sort(\"input_length\")\n",
    "\n",
    "valid_ds.set_format(type=None, columns=[\"id\", \"input_ids\", \"attention_mask\", \"generated\"])\n",
    "valid_ids = valid_df[\"id\"]\n",
    "\n",
    "test_ds = test_ds.sort(\"input_length\")\n",
    "\n",
    "test_ds.set_format(type=None, columns=[\"id\", \"input_ids\", \"attention_mask\", \"generated\"])\n",
    "test_ids = test_ds[\"id\"]\n",
    "\n",
    "# ---\n",
    "kwargs = dict(\n",
    "    train_ds=train_ds,\n",
    "    prompt_ids=prompt_ids,\n",
    "    prompt2ids=prompt2ids,\n",
    ")\n",
    "\n",
    "data_collector_train = AiCollatorTrain(\n",
    "    tokenizer=tokenizer,\n",
    "    pad_to_multiple_of=64,\n",
    "    kwargs=kwargs,\n",
    ")\n",
    "\n",
    "data_collector = AiCollator(tokenizer=tokenizer, pad_to_multiple_of=64)\n",
    "\n",
    "train_dl = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collector_train,\n",
    ")\n",
    "\n",
    "valid_dl = DataLoader(\n",
    "    valid_ds,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    collate_fn=data_collector,\n",
    ")\n",
    "\n",
    "test_dl = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    collate_fn=data_collector,\n",
    ")\n",
    "\n",
    "accelerator.print(\"data preparation done...\")\n",
    "print_line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config for the current run:\n",
      "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
      "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
      "creating the LLM Detection model...\n",
      "initializing the Rank Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\Kiaver\\.cache\\huggingface\\hub\\models--microsoft--deberta-v3-xsmall\\snapshots\\4b419818330868dff6a60ad3e6b1c730f8b8c0c6\\config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 384,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1536,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"legacy\": true,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 6,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 384,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.51.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Kiaver\\.cache\\huggingface\\hub\\models--microsoft--deberta-v3-xsmall\\snapshots\\4b419818330868dff6a60ad3e6b1c730f8b8c0c6\\pytorch_model.bin\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-xsmall were not used when initializing DebertaV2Model: ['embeddings.word_embeddings._weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.bias', 'mask_predictions.classifier.weight', 'mask_predictions.dense.bias', 'mask_predictions.dense.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of DebertaV2Model were initialized from the model checkpoint at microsoft/deberta-v3-xsmall.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2Model for predictions without further training.\n",
      "Attempting to create safetensors variant\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
      "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
      "creating the optimizer...\n",
      "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
      "# training updates per epoch: 1850\n",
      "# training steps: 1850\n",
      "# warmup steps: 185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STEP:     1/ 1850. LR: 0.1081. Loss: 0.7417. :   0%|          | 1/1850 [00:00<17:15,  1.78it/s]Safetensors PR exists\n",
      "100%|██████████| 347/347 [00:03<00:00, 90.74it/s]27%|██▋       | 500/1850 [00:31<01:18, 17.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
      ">>> Epoch 1 | Step 499 | Total Step 500 | Time: 0m35s\n",
      "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
      ">>> Current LB (AUC) = 0.9919, R2 = 0.9623, F1 = 0.988, recall = 0.9939\n",
      "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STEP:   502/ 1850. LR: 18.2639. Loss: 0.5816. :  27%|██▋       | 502/1850 [00:36<15:26,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 347/347 [00:03<00:00, 91.46it/s]54%|█████▍    | 1000/1850 [01:06<00:48, 17.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
      ">>> Epoch 1 | Step 999 | Total Step 1000 | Time: 1m10s\n",
      "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
      ">>> Current LB (AUC) = 0.9961, R2 = 0.978, F1 = 0.993, recall = 1.0\n",
      "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STEP:  1002/ 1850. LR: 10.2924. Loss: 0.5587. :  54%|█████▍    | 1002/1850 [01:10<09:40,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 347/347 [00:04<00:00, 86.50it/s]1%|████████  | 1500/1850 [01:41<00:22, 15.88it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
      ">>> Epoch 1 | Step 1499 | Total Step 1500 | Time: 1m45s\n",
      "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
      ">>> Current LB (AUC) = 0.9974, R2 = 0.9906, F1 = 0.997, recall = 0.996\n",
      "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STEP:  1502/ 1850. LR: 2.0794. Loss: 0.5554. :  81%|████████  | 1502/1850 [01:45<04:12,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STEP:  1850/ 1850. LR: 0.0000. Loss: 0.5548. : 100%|██████████| 1850/1850 [02:07<00:00, 17.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 116/116 [00:01<00:00, 86.50it/s]\n",
      "STEP:  1850/ 1850. LR: 0.0000. Loss: 0.5548. : 100%|██████████| 1850/1850 [02:08<00:00, 14.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
      ">>> Final performance on test AUC = 1.0, R2 = 1.0, F1 = 1.0, recall = 1.0\n",
      "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# -------- Evaluation -------------------------------------------------------------#\n",
    "def run_evaluation(accelerator, model, valid_dl, valid_ids):\n",
    "    model.eval()\n",
    "\n",
    "    all_predictions = []\n",
    "    all_truths = []\n",
    "\n",
    "    progress_bar = tqdm(\n",
    "        range(len(valid_dl)), disable=not accelerator.is_local_main_process\n",
    "    )\n",
    "\n",
    "    for batch in valid_dl:\n",
    "        with torch.no_grad():\n",
    "            logits, _ = model(**batch)\n",
    "            logits = logits.reshape(-1)\n",
    "        predictions = torch.sigmoid(logits)\n",
    "        predictions, references = accelerator.gather_for_metrics(\n",
    "            (predictions, batch[\"labels\"].to(torch.long).reshape(-1))\n",
    "        )\n",
    "        predictions, references = (\n",
    "            predictions.cpu().numpy().tolist(),\n",
    "            references.cpu().numpy().tolist(),\n",
    "        )\n",
    "\n",
    "        all_predictions.extend(predictions)\n",
    "        all_truths.extend(references)\n",
    "\n",
    "        progress_bar.update(1)\n",
    "    progress_bar.close()\n",
    "\n",
    "    # compute metric\n",
    "    eval_dict = compute_metrics(all_predictions, all_truths)\n",
    "\n",
    "    result_df = pd.DataFrame()\n",
    "    result_df[\"id\"] = valid_ids\n",
    "    result_df[\"predictions\"] = all_predictions\n",
    "    result_df[\"truths\"] = all_truths\n",
    "\n",
    "    oof_df = deepcopy(result_df)\n",
    "    oof_df = oof_df.rename(columns={\"predictions\": \"generated\"})\n",
    "    oof_df = oof_df[[\"id\", \"generated\"]].copy()\n",
    "\n",
    "    to_return = {\n",
    "        \"scores\": eval_dict,\n",
    "        \"result_df\": result_df,\n",
    "        \"oof_df\": oof_df,\n",
    "    }\n",
    "\n",
    "    return to_return\n",
    "\n",
    "\n",
    "# -------- Main Function ---------------------------------------------------------#\n",
    "def run_training(train_dl, valid_dl, test_dl):\n",
    "    # --- show batch -------------------------------------------------------------------#\n",
    "    # print_line()\n",
    "\n",
    "    # for b in train_dl:\n",
    "    #     break\n",
    "    # show_batch(b, tokenizer, task=\"training\", print_fn=print, n_examples=4)\n",
    "\n",
    "    # print_line()\n",
    "\n",
    "    # for b in valid_dl:\n",
    "    #     break\n",
    "    # show_batch(b, tokenizer, task=\"validation\", print_fn=accelerator.print)\n",
    "\n",
    "    # print_line()\n",
    "\n",
    "    # ------- Config -------------------------------------------------------------------#\n",
    "    accelerator.print(\"config for the current run:\")\n",
    "    print_line()\n",
    "\n",
    "    # ------- Model --------------------------------------------------------------------#\n",
    "    print_line()\n",
    "    print(\"creating the LLM Detection model...\")\n",
    "    model = AiModel(accelerator.device)\n",
    "    print_line()\n",
    "\n",
    "    # ------- Optimizer ----------------------------------------------------------------#\n",
    "    print_line()\n",
    "    print(\"creating the optimizer...\")\n",
    "    optimizer = get_optimizer(model)\n",
    "    # ------- Prepare -------------------------------------------------------------------#\n",
    "\n",
    "    model, optimizer, train_dl, valid_dl, test_dl = accelerator.prepare(\n",
    "        model, optimizer, train_dl, valid_dl, test_dl\n",
    "    )\n",
    "\n",
    "    # ------- Scheduler -----------------------------------------------------------------#\n",
    "    print_line()\n",
    "    num_epochs = 1\n",
    "    grad_accumulation_steps = 1\n",
    "    warmup_pct = 0.1\n",
    "\n",
    "    num_update_steps_per_epoch = len(train_dl) // grad_accumulation_steps\n",
    "    num_training_steps = num_epochs * num_update_steps_per_epoch\n",
    "    num_warmup_steps = int(warmup_pct * num_training_steps)\n",
    "\n",
    "    accelerator.print(f\"# training updates per epoch: {num_update_steps_per_epoch}\")\n",
    "    accelerator.print(f\"# training steps: {num_training_steps}\")\n",
    "    accelerator.print(f\"# warmup steps: {num_warmup_steps}\")\n",
    "\n",
    "    scheduler = get_cosine_schedule_with_warmup(\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=num_warmup_steps,\n",
    "        num_training_steps=num_training_steps,\n",
    "    )\n",
    "\n",
    "    # ------- training setup --------------------------------------------------------------#\n",
    "    best_lb = -1  # track recall@1000\n",
    "\n",
    "    patience_tracker = 0\n",
    "    current_iteration = 0\n",
    "\n",
    "    # ------- training  --------------------------------------------------------------------#\n",
    "    start_time = time.time()\n",
    "    accelerator.wait_for_everyone()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # close and reset progress bar\n",
    "        if epoch != 0:\n",
    "            progress_bar.close()\n",
    "\n",
    "        progress_bar = tqdm(\n",
    "            range(num_update_steps_per_epoch),\n",
    "            disable=not accelerator.is_local_main_process,\n",
    "        )\n",
    "        loss_meter = AverageMeter()\n",
    "\n",
    "        # Training ------\n",
    "        model.train()\n",
    "        for step, batch in enumerate(train_dl):\n",
    "            with accelerator.accumulate(model):\n",
    "                _, loss = model(**batch)\n",
    "                accelerator.backward(loss)\n",
    "\n",
    "                if accelerator.sync_gradients:\n",
    "                    accelerator.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "                    optimizer.step()  # gradient_state.sync_gradients check is performed inside optimizer.step\n",
    "                    scheduler.step()\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                loss_meter.update(loss.item())\n",
    "\n",
    "            if accelerator.sync_gradients:\n",
    "                progress_bar.set_description(\n",
    "                    f\"STEP: {current_iteration + 1:5}/{num_update_steps_per_epoch:5}. \"\n",
    "                    f\"LR: {get_lr(optimizer):.4f}. \"\n",
    "                    f\"Loss: {loss_meter.avg:.4f}. \"\n",
    "                )\n",
    "\n",
    "                progress_bar.update(1)\n",
    "                current_iteration += 1\n",
    "\n",
    "            # >--------------------------------------------------|\n",
    "            # >-- evaluation ------------------------------------|\n",
    "            # >--------------------------------------------------|\n",
    "\n",
    "            if (accelerator.sync_gradients) & (current_iteration % 500 == 0):\n",
    "                # set model in eval mode\n",
    "                model.eval()\n",
    "                eval_response = run_evaluation(accelerator, model, valid_dl, valid_ids)\n",
    "\n",
    "                scores_dict = eval_response[\"scores\"]\n",
    "                result_df = eval_response[\"result_df\"]\n",
    "                oof_df = eval_response[\"oof_df\"]\n",
    "                lb = scores_dict[\"lb\"]\n",
    "                r2 = scores_dict[\"r2\"]\n",
    "                f1 = scores_dict[\"f1\"]\n",
    "                recall = scores_dict[\"recall\"]\n",
    "\n",
    "                print_line()\n",
    "                et = as_minutes(time.time() - start_time)\n",
    "                accelerator.print(\n",
    "                    f\">>> Epoch {epoch + 1} | Step {step} | Total Step {current_iteration} | Time: {et}\"\n",
    "                )\n",
    "                print_line()\n",
    "                accelerator.print(\n",
    "                    f\">>> Current LB (AUC) = {round(lb, 4)}, R2 = {r2}, F1 = {f1}, recall = {recall}\"\n",
    "                )\n",
    "\n",
    "                print_line()\n",
    "\n",
    "                is_best = False\n",
    "                if lb >= best_lb:\n",
    "                    best_lb = lb\n",
    "                    is_best = True\n",
    "                    patience_tracker = 0\n",
    "\n",
    "                    # -----\n",
    "                    best_dict = dict()\n",
    "                    for k, v in scores_dict.items():\n",
    "                        best_dict[f\"{k}_at_best\"] = v\n",
    "                else:\n",
    "                    patience_tracker += 1\n",
    "\n",
    "                if is_best:\n",
    "                    oof_df.to_csv(\n",
    "                        os.path.join(\"../models/r_ranking\", \"oof_df_best.csv\"),\n",
    "                        index=False,\n",
    "                    )\n",
    "                    result_df.to_csv(\n",
    "                        os.path.join(\"../models/r_ranking\", \"result_df_best.csv\"),\n",
    "                        index=False,\n",
    "                    )\n",
    "                else:\n",
    "                    accelerator.print(f\">>> patience reached {patience_tracker}/{10}\")\n",
    "                    accelerator.print(f\">>> current best score: {round(best_lb, 4)}\")\n",
    "\n",
    "                oof_df.to_csv(\n",
    "                    os.path.join(\"../models/r_ranking\", \"oof_df_last.csv\"), index=False\n",
    "                )\n",
    "                result_df.to_csv(\n",
    "                    os.path.join(\"../models/r_ranking\", \"result_df_last.csv\"),\n",
    "                    index=False,\n",
    "                )\n",
    "\n",
    "                # saving -----\n",
    "                accelerator.wait_for_everyone()\n",
    "                unwrapped_model = accelerator.unwrap_model(model)\n",
    "                model_state = {\n",
    "                    \"step\": current_iteration,\n",
    "                    \"epoch\": epoch + 1,\n",
    "                    \"state_dict\": unwrapped_model.state_dict(),\n",
    "                    \"lb\": lb,\n",
    "                }\n",
    "\n",
    "                if accelerator.is_main_process:\n",
    "                    save_checkpoint(model_state, is_best=is_best)\n",
    "\n",
    "                # -- post eval\n",
    "                model.train()\n",
    "                torch.cuda.empty_cache()\n",
    "                print_line()\n",
    "\n",
    "                # early stopping ----\n",
    "                if patience_tracker >= 10:\n",
    "                    print(\"stopping early\")\n",
    "                    model.eval()\n",
    "                    accelerator.end_training()\n",
    "                    return\n",
    "\n",
    "    # check on test\n",
    "    print_line()\n",
    "    model.eval()\n",
    "    eval_response = run_evaluation(accelerator, model, test_dl, test_ids)\n",
    "\n",
    "    scores_dict = eval_response[\"scores\"]\n",
    "    result_df = eval_response[\"result_df\"]\n",
    "    oof_df = eval_response[\"oof_df\"]\n",
    "    lb = scores_dict[\"lb\"]\n",
    "    r2 = scores_dict[\"r2\"]\n",
    "    f1 = scores_dict[\"f1\"]\n",
    "    recall = scores_dict[\"recall\"]\n",
    "    print_line()\n",
    "    accelerator.print(\n",
    "        f\">>> Final performance on test AUC = {round(lb, 4)}, R2 = {r2}, F1 = {f1}, recall = {recall}\"\n",
    "    )\n",
    "    print_line()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_training(train_dl, valid_dl, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing the Rank Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\Kiaver\\.cache\\huggingface\\hub\\models--microsoft--deberta-v3-xsmall\\snapshots\\4b419818330868dff6a60ad3e6b1c730f8b8c0c6\\config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 384,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1536,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"legacy\": true,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 6,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 384,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.51.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Kiaver\\.cache\\huggingface\\hub\\models--microsoft--deberta-v3-xsmall\\snapshots\\4b419818330868dff6a60ad3e6b1c730f8b8c0c6\\pytorch_model.bin\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-xsmall were not used when initializing DebertaV2Model: ['embeddings.word_embeddings._weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.bias', 'mask_predictions.classifier.weight', 'mask_predictions.dense.bias', 'mask_predictions.dense.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of DebertaV2Model were initialized from the model checkpoint at microsoft/deberta-v3-xsmall.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2Model for predictions without further training.\n",
      "  2%|▏         | 2/116 [00:00<00:09, 12.20it/s]Attempting to create safetensors variant\n",
      " 10%|█         | 12/116 [00:00<00:07, 14.67it/s]Safetensors PR exists\n",
      "100%|██████████| 116/116 [00:10<00:00, 10.82it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'scores': {'lb': 1.0, 'r2': 1.0, 'f1': 1.0, 'recall': 1.0},\n",
       " 'result_df':        id  predictions  truths\n",
       " 0     358     0.954265       1\n",
       " 1    1906     0.958759       1\n",
       " 2     207     0.975657       1\n",
       " 3    1579     0.820372       1\n",
       " 4    3885     0.030616       0\n",
       " ..    ...          ...     ...\n",
       " 458   332     0.981398       1\n",
       " 459   462     0.980917       1\n",
       " 460  6032     0.029438       0\n",
       " 461  8870     0.027041       0\n",
       " 462   783     0.980884       1\n",
       " \n",
       " [463 rows x 3 columns],\n",
       " 'oof_df':        id  generated\n",
       " 0     358   0.954265\n",
       " 1    1906   0.958759\n",
       " 2     207   0.975657\n",
       " 3    1579   0.820372\n",
       " 4    3885   0.030616\n",
       " ..    ...        ...\n",
       " 458   332   0.981398\n",
       " 459   462   0.980917\n",
       " 460  6032   0.029438\n",
       " 461  8870   0.027041\n",
       " 462   783   0.980884\n",
       " \n",
       " [463 rows x 2 columns]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"./checkpoints_path/detect_ai_model_last.pth.tar\"\n",
    "model_test = AiModel(accelerator.device)\n",
    "ckpt = torch.load(checkpoint_path, weights_only=False)\n",
    "model_test.load_state_dict(ckpt[\"state_dict\"])\n",
    "eval_response = run_evaluation(accelerator, model_test, test_dl, test_ids)\n",
    "eval_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predictions</th>\n",
       "      <th>truths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>358</td>\n",
       "      <td>0.954265</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1906</td>\n",
       "      <td>0.958759</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>207</td>\n",
       "      <td>0.975657</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1579</td>\n",
       "      <td>0.820372</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3885</td>\n",
       "      <td>0.030616</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>332</td>\n",
       "      <td>0.981398</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>462</td>\n",
       "      <td>0.980917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>6032</td>\n",
       "      <td>0.029438</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>8870</td>\n",
       "      <td>0.027041</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>783</td>\n",
       "      <td>0.980884</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>463 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  predictions  truths\n",
       "0     358     0.954265       1\n",
       "1    1906     0.958759       1\n",
       "2     207     0.975657       1\n",
       "3    1579     0.820372       1\n",
       "4    3885     0.030616       0\n",
       "..    ...          ...     ...\n",
       "458   332     0.981398       1\n",
       "459   462     0.980917       1\n",
       "460  6032     0.029438       0\n",
       "461  8870     0.027041       0\n",
       "462   783     0.980884       1\n",
       "\n",
       "[463 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_response[\"result_df\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
