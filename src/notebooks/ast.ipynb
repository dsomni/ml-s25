{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import tree_sitter_python as tspython\n",
    "from tree_sitter import Language, Parser\n",
    "\n",
    "PY_LANGUAGE = Language(tspython.language())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4e1a40ef64f9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set up parser\n",
    "parser = Parser(PY_LANGUAGE)\n",
    "\n",
    "# Sample code snippets and their binary labels (e.g., 0 = clean, 1 = vulnerable)\n",
    "samples = [\n",
    "    (b\"def add(a, b): return a + b\", 0),\n",
    "    (b\"def eval_input(): eval(input())\", 1),  # potentially dangerous use\n",
    "]\n",
    "\n",
    "# List all possible node types we'll count\n",
    "node_types = set()\n",
    "\n",
    "\n",
    "def walk_tree(node, types):\n",
    "    types.append(node.type)\n",
    "    for child in node.children:\n",
    "        walk_tree(child, types)\n",
    "\n",
    "\n",
    "# First pass: gather all node types\n",
    "for code, _ in samples:\n",
    "    tree = parser.parse(code)\n",
    "    types = []\n",
    "    walk_tree(tree.root_node, types)\n",
    "    node_types.update(types)\n",
    "\n",
    "# Create fixed feature vector mapping\n",
    "node_types = sorted(node_types)\n",
    "type_to_idx = {typ: i for i, typ in enumerate(node_types)}\n",
    "\n",
    "\n",
    "def code_to_feature_vector(code):\n",
    "    tree = parser.parse(code)\n",
    "    types = []\n",
    "    walk_tree(tree.root_node, types)\n",
    "    counts = Counter(types)\n",
    "    feature_vector = [counts.get(typ, 0) for typ in node_types]\n",
    "    return torch.tensor(feature_vector, dtype=torch.float32)\n",
    "\n",
    "\n",
    "df_gen = pd.read_csv(\"../../data/generated/gen_solutions.csv\")\n",
    "df_gen = df_gen[[\"spec\", \"solution\"]]\n",
    "df_gen.columns = [\"task\", \"text\"]\n",
    "df_gen[\"generated\"] = 1\n",
    "df_real = pd.read_csv(\"../../data/db_attempts.csv\")\n",
    "df_real = df_real[[\"task\", \"programText\"]]\n",
    "df_real.columns = [\"task\", \"text\"]\n",
    "df_real[\"generated\"] = 0\n",
    "df = pd.concat([df_gen, df_real], axis=0, ignore_index=True)\n",
    "df = df.dropna(subset=[\"text\"])\n",
    "df[\"text\"] = df[\"text\"].astype(str)\n",
    "df.drop_duplicates()\n",
    "df[\"id\"] = df.index + 1\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "train_df, val_prep = train_test_split(df, test_size=0.2, stratify=df[\"generated\"])\n",
    "valid_df, test_df = train_test_split(\n",
    "    val_prep, test_size=0.25, stratify=val_prep[\"generated\"]\n",
    ")\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "valid_df = valid_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "X = torch.stack([code_to_feature_vector(code) for code, _ in samples])\n",
    "y = torch.tensor([label for _, label in samples], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79d5db92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(',\n",
       " ')',\n",
       " '+',\n",
       " ',',\n",
       " ':',\n",
       " 'argument_list',\n",
       " 'binary_operator',\n",
       " 'block',\n",
       " 'call',\n",
       " 'def',\n",
       " 'expression_statement',\n",
       " 'function_definition',\n",
       " 'identifier',\n",
       " 'module',\n",
       " 'parameters',\n",
       " 'return',\n",
       " 'return_statement']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1dde22ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Loss: 0.0004\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class CodeClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=32):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, 2)  # binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.relu(self.fc1(x)))\n",
    "\n",
    "\n",
    "model = CodeClassifier(input_dim=len(node_types))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Simple training loop\n",
    "for epoch in range(30):\n",
    "    outputs = model(X)\n",
    "    loss = criterion(outputs, y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f\"Final Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f6c54c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
