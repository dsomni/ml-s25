{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58b6999c",
   "metadata": {},
   "source": [
    "# Solution based on AST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01c8a306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tree_sitter_python as tspython\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from tree_sitter import Language, Parser\n",
    "\n",
    "PY_LANGUAGE = Language(tspython.language())\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580a6318",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55860f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 420):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978ce47c",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb97800f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size: 12428\n",
      "\n",
      "Train size: 8699\n",
      "Validation size: 2610\n",
      "Test size: 1119\n"
     ]
    }
   ],
   "source": [
    "set_seed()\n",
    "df = pd.read_csv(\"../../data/generated/dataset.csv\")\n",
    "\n",
    "print(f\"Total size: {len(df)}\\n\")\n",
    "\n",
    "train_df, val_prep = train_test_split(df, test_size=0.3, stratify=df[\"generated\"])\n",
    "valid_df, test_df = train_test_split(\n",
    "    val_prep, test_size=0.3, stratify=val_prep[\"generated\"]\n",
    ")\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "valid_df = valid_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "print(f\"Train size: {len(train_df)}\")\n",
    "print(f\"Validation size: {len(valid_df)}\")\n",
    "print(f\"Test size: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2d8a9d",
   "metadata": {},
   "source": [
    "Check that the data is balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d43e53df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean generated (train): 0.5212093344062536\n",
      "Mean generated (validation): 0.5210727969348659\n",
      "Mean generated (test): 0.5210008936550492\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean generated (train): {train_df['generated'].mean()}\")\n",
    "print(f\"Mean generated (validation): {valid_df['generated'].mean()}\")\n",
    "print(f\"Mean generated (test): {test_df['generated'].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066cb0c6",
   "metadata": {},
   "source": [
    "## Dataset building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f4e1a40ef64f9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = Parser(PY_LANGUAGE)\n",
    "node_types = set()\n",
    "\n",
    "\n",
    "def walk_tree(node, types):\n",
    "    types.append(node.type)\n",
    "    for child in node.children:\n",
    "        walk_tree(child, types)\n",
    "\n",
    "\n",
    "def code_to_feature_vector(code: bytes, device=DEVICE) -> torch.Tensor:\n",
    "    tree = parser.parse(code)\n",
    "    types = []\n",
    "    walk_tree(tree.root_node, types)\n",
    "    counts = Counter(types)\n",
    "    feature_vector = [counts.get(typ, 0) for typ in node_types]\n",
    "    return torch.tensor(feature_vector, dtype=torch.float32, device=device)\n",
    "\n",
    "\n",
    "# Gather all node types\n",
    "for _, row in train_df.iterrows():\n",
    "    tree = parser.parse(str.encode(row[\"code\"]))\n",
    "    types = []\n",
    "    walk_tree(tree.root_node, types)\n",
    "    node_types.update(types)\n",
    "\n",
    "node_types = sorted(node_types)\n",
    "type_to_idx = {typ: i for i, typ in enumerate(node_types)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7c9788",
   "metadata": {},
   "source": [
    "Save node types for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1db913e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/ast/node_types.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(node_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6474104a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASTDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "    def __getitem__(self, index) -> tuple[str, torch.Tensor, float]:\n",
    "        raw_code = self.dataframe[\"code\"].iloc[index]\n",
    "        return (\n",
    "            raw_code,\n",
    "            code_to_feature_vector(raw_code.encode(\"utf-8\")),\n",
    "            float(self.dataframe[\"generated\"].iloc[index]),\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "\n",
    "data_train = ASTDataset(dataframe=train_df)\n",
    "dataloader_train = DataLoader(data_train, batch_size=64)\n",
    "data_val = ASTDataset(dataframe=valid_df)\n",
    "dataloader_val = DataLoader(data_val, batch_size=128)\n",
    "data_test = ASTDataset(dataframe=test_df)\n",
    "dataloader_test = DataLoader(data_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8911781",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c390f5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIDetector(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dim1: int = 64, hidden_dim2: int = 32):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_dim1, hidden_dim2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_dim2, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32630637",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dde22ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 136/136 [00:01<00:00, 72.49it/s]\n",
      "Validation: 100%|██████████| 21/21 [00:00<00:00, 41.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RECALL: 0.6412 | ROC_AUC: 0.6126 | F1: 0.6337 | MAE: 0.4041 | MSE: 0.2727\n",
      "\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 136/136 [00:01<00:00, 78.74it/s]\n",
      "Validation: 100%|██████████| 21/21 [00:00<00:00, 42.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RECALL: 0.5941 | ROC_AUC: 0.6495 | F1: 0.6370 | MAE: 0.3605 | MSE: 0.2784\n",
      "\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 136/136 [00:01<00:00, 75.72it/s]\n",
      "Validation: 100%|██████████| 21/21 [00:00<00:00, 37.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RECALL: 0.6324 | ROC_AUC: 0.6630 | F1: 0.6608 | MAE: 0.3439 | MSE: 0.2796\n",
      "\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 136/136 [00:02<00:00, 64.55it/s]\n",
      "Validation: 100%|██████████| 21/21 [00:00<00:00, 39.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RECALL: 0.6618 | ROC_AUC: 0.6693 | F1: 0.6757 | MAE: 0.3359 | MSE: 0.2789\n",
      "\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 136/136 [00:02<00:00, 64.98it/s]\n",
      "Validation: 100%|██████████| 21/21 [00:00<00:00, 40.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RECALL: 0.8074 | ROC_AUC: 0.6677 | F1: 0.7205 | MAE: 0.3361 | MSE: 0.2883\n",
      "\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 136/136 [00:01<00:00, 68.14it/s]\n",
      "Validation: 100%|██████████| 21/21 [00:00<00:00, 35.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RECALL: 0.7632 | ROC_AUC: 0.6832 | F1: 0.7173 | MAE: 0.3205 | MSE: 0.2752\n",
      "\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 136/136 [00:02<00:00, 59.78it/s]\n",
      "Validation: 100%|██████████| 21/21 [00:00<00:00, 39.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RECALL: 0.7735 | ROC_AUC: 0.6916 | F1: 0.7255 | MAE: 0.3145 | MSE: 0.2725\n",
      "\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 136/136 [00:02<00:00, 66.54it/s]\n",
      "Validation: 100%|██████████| 21/21 [00:00<00:00, 32.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RECALL: 0.6537 | ROC_AUC: 0.6972 | F1: 0.6910 | MAE: 0.3083 | MSE: 0.2652\n",
      "\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 136/136 [00:02<00:00, 61.12it/s]\n",
      "Validation: 100%|██████████| 21/21 [00:00<00:00, 32.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RECALL: 0.6346 | ROC_AUC: 0.6985 | F1: 0.6849 | MAE: 0.3054 | MSE: 0.2661\n",
      "\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 136/136 [00:02<00:00, 56.90it/s]\n",
      "Validation: 100%|██████████| 21/21 [00:00<00:00, 30.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RECALL: 0.6493 | ROC_AUC: 0.7038 | F1: 0.6939 | MAE: 0.2978 | MSE: 0.2592\n",
      "\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "def compute_metrics(predictions: list[float], labels: list[float]) -> dict:\n",
    "    predictions_rounded = [round(x) for x in predictions]\n",
    "    labels_rounded = [round(x) for x in labels]\n",
    "\n",
    "    return {\n",
    "        \"recall\": recall_score(labels_rounded, predictions_rounded),\n",
    "        \"roc_auc\": roc_auc_score(labels_rounded, predictions_rounded),\n",
    "        \"f1\": f1_score(labels_rounded, predictions_rounded),\n",
    "        \"mae\": mean_absolute_error(labels, predictions),\n",
    "        \"mse\": mean_squared_error(labels, predictions),\n",
    "    }\n",
    "\n",
    "\n",
    "def metrics_str(metrics: dict) -> str:\n",
    "    return \" | \".join([f\"{key.upper()}: {value:.4f}\" for key, value in metrics.items()])\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    model: nn.Module, dataloader: DataLoader, criterion, optimizer: optim.Optimizer\n",
    "):\n",
    "    losses = []\n",
    "    model.train()\n",
    "    for _, code, label in tqdm(dataloader, desc=\"Training\"):\n",
    "        code, label = code.float().to(DEVICE), label.float().to(DEVICE)\n",
    "        outputs = model(code)\n",
    "        outputs = outputs.squeeze()\n",
    "        loss = criterion(outputs, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "    return np.mean(losses)\n",
    "\n",
    "\n",
    "def evaluate_model(model: nn.Module, dataloader: DataLoader) -> dict:\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        all_predictions = []\n",
    "        all_truths = []\n",
    "        for _, code, label in tqdm(dataloader, desc=\"Validation\"):\n",
    "            code, label = code.float().to(DEVICE), label.float().to(DEVICE)\n",
    "            outputs = model(code)\n",
    "            outputs = outputs.squeeze()\n",
    "\n",
    "            all_predictions.extend(outputs.detach().cpu().numpy().tolist())\n",
    "            all_truths.extend(label.detach().cpu().numpy().tolist())\n",
    "\n",
    "        return compute_metrics(all_predictions, all_truths)\n",
    "\n",
    "\n",
    "def train_eval_loop(\n",
    "    model: nn.Module,\n",
    "    dataloader_train: DataLoader,\n",
    "    dataloader_val: DataLoader,\n",
    "    criterion,\n",
    "    optimizer: optim.Optimizer,\n",
    "    epochs: int = 5,\n",
    "    early_stopping: int = 3,\n",
    "    maximize: str = \"recall\",\n",
    "    save_path: str = \"../../data/ast/best_model.pth\",\n",
    "):\n",
    "    set_seed()\n",
    "    best_score = 0 if maximize == \"recall\" else float(\"inf\")\n",
    "    no_improvement = 0\n",
    "    mean_losses = []\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f\"Epoch {epoch}/{epochs}\")\n",
    "        mean_loss = train_model(model, dataloader_train, criterion, optimizer)\n",
    "        metrics = evaluate_model(model, dataloader_val)\n",
    "\n",
    "        mean_losses.append(mean_loss)\n",
    "        print(f\"\\n{metrics_str(metrics)}\\n\")\n",
    "\n",
    "        score = metrics[maximize]\n",
    "        if (maximize == \"recall\" and score > best_score) or (\n",
    "            maximize == \"mae\" and score < best_score\n",
    "        ):\n",
    "            no_improvement = 0\n",
    "            best_score = score\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "        else:\n",
    "            no_improvement += 1\n",
    "        if no_improvement >= early_stopping:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    return mean_losses\n",
    "\n",
    "\n",
    "set_seed()\n",
    "model = AIDetector(input_dim=len(node_types)).to(DEVICE)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# criterion = nn.MSELoss()\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "losses = train_eval_loop(\n",
    "    model,\n",
    "    dataloader_train,\n",
    "    dataloader_val,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    epochs=50,\n",
    "    early_stopping=5,\n",
    "    maximize=\"recall\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360558b2",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83b7bea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model: nn.Module, dataloader: DataLoader) -> tuple[pd.DataFrame, dict]:\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        all_predictions = []\n",
    "        all_truths = []\n",
    "        all_codes = []\n",
    "        for real_code, code, label in tqdm(dataloader, desc=\"Validation\"):\n",
    "            code, label = code.float().to(DEVICE), label.float().to(DEVICE)\n",
    "            outputs = model(code)\n",
    "            outputs = outputs.squeeze()\n",
    "\n",
    "            all_predictions.extend(outputs.detach().cpu().numpy().tolist())\n",
    "            all_truths.extend(label.detach().cpu().numpy().tolist())\n",
    "            all_codes.extend(real_code)\n",
    "\n",
    "        test_df = pd.DataFrame(\n",
    "            {\"code\": all_codes, \"real\": all_truths, \"predicted\": all_predictions}\n",
    "        )\n",
    "        return test_df, compute_metrics(all_predictions, all_truths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bad998ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 9/9 [00:00<00:00, 24.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RECALL: 0.8113 | ROC_AUC: 0.6603 | F1: 0.7172 | MAE: 0.3417 | MSE: 0.2977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_model = AIDetector(input_dim=len(node_types)).to(DEVICE)\n",
    "best_model.load_state_dict(torch.load(\"../../data/ast/best_model.pth\"))\n",
    "test_df, test_metrics = test_model(best_model, dataloader_test)\n",
    "print(metrics_str(test_metrics))\n",
    "\n",
    "test_df.to_csv(\"../../data/ast/test_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ba93e1",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e5fa4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_ai_code(code: str) -> float:\n",
    "    with open(\"../../data/ast/node_types.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "        node_types_loaded = f.readlines()\n",
    "\n",
    "    loaded_model = AIDetector(input_dim=len(node_types_loaded))\n",
    "    loaded_model.load_state_dict(torch.load(\"../../data/ast/best_model.pth\"))\n",
    "\n",
    "    code_vectorized = code_to_feature_vector(\n",
    "        code.encode(\"utf-8\"), device=torch.device(\"cpu\")\n",
    "    ).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        prediction = loaded_model(code_vectorized).squeeze().cpu().item()\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a29df5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************\n",
      "CODE:\n",
      "\n",
      "a,b = map(int, input().split())\n",
      "if a > b:\n",
      "    return 1\n",
      "return 0\n",
      "\n",
      "PREDICTION: 0.9976\n",
      "\n",
      "***************\n",
      "CODE:\n",
      "\n",
      "x, y = map(int, input().split())\n",
      "return int(x>y)\n",
      "\n",
      "PREDICTION: 0.9946\n",
      "\n",
      "***************\n",
      "CODE:\n",
      "\n",
      "l = map(int, input().split())\n",
      "if l[0] > l[1] :\n",
      "    return 1\n",
      "else:\n",
      "    return 0\n",
      "\n",
      "PREDICTION: 0.9703\n",
      "\n"
     ]
    }
   ],
   "source": [
    "code1 = \"\"\"\n",
    "a,b = map(int, input().split())\n",
    "if a > b:\n",
    "    return 1\n",
    "return 0\n",
    "\"\"\"\n",
    "\n",
    "code2 = \"\"\"\n",
    "x, y = map(int, input().split())\n",
    "return int(x>y)\n",
    "\"\"\"\n",
    "\n",
    "code3 = \"\"\"\n",
    "l = map(int, input().split())\n",
    "if l[0] > l[1] :\n",
    "    return 1\n",
    "else:\n",
    "    return 0\n",
    "\"\"\"\n",
    "for c in [code1, code2, code3]:\n",
    "    print(f\"{'*' * 15}\\nCODE:\\n{c}\\nPREDICTION: {detect_ai_code(c):.4f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
