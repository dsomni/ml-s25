{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import tree_sitter_python as tspython\n",
    "from tree_sitter import Language, Parser\n",
    "\n",
    "PY_LANGUAGE = Language(tspython.language())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9f4e1a40ef64f9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set up parser\n",
    "parser = Parser(PY_LANGUAGE)\n",
    "\n",
    "# Sample code snippets and their binary labels (e.g., 0 = clean, 1 = vulnerable)\n",
    "samples = [\n",
    "    (b\"def add(a, b): return a + b\", 0),\n",
    "    (b\"def eval_input(): eval(input())\", 1),  # potentially dangerous use\n",
    "]\n",
    "\n",
    "# List all possible node types we'll count\n",
    "node_types = set()\n",
    "\n",
    "\n",
    "def walk_tree(node, types):\n",
    "    types.append(node.type)\n",
    "    for child in node.children:\n",
    "        walk_tree(child, types)\n",
    "\n",
    "\n",
    "def code_to_feature_vector(code):\n",
    "    tree = parser.parse(code)\n",
    "    types = []\n",
    "    walk_tree(tree.root_node, types)\n",
    "    counts = Counter(types)\n",
    "    feature_vector = [counts.get(typ, 0) for typ in node_types]\n",
    "    return torch.tensor(feature_vector, dtype=torch.float32)\n",
    "\n",
    "\n",
    "df_gen = pd.read_csv(\"../../data/generated/gen_solutions.csv\")\n",
    "df_gen = df_gen[[\"spec\", \"solution\"]]\n",
    "df_gen.columns = [\"task\", \"text\"]\n",
    "df_gen[\"generated\"] = 1\n",
    "df_real = pd.read_csv(\"../../data/db_attempts.csv\")\n",
    "df_real = df_real[[\"task\", \"programText\"]]\n",
    "df_real.columns = [\"task\", \"text\"]\n",
    "df_real[\"generated\"] = 0\n",
    "df = pd.concat([df_gen, df_real], axis=0, ignore_index=True)\n",
    "df = df.dropna(subset=[\"text\"])\n",
    "df[\"text\"] = df[\"text\"].astype(str)\n",
    "df.drop_duplicates()\n",
    "df[\"id\"] = df.index + 1\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "train_df, val_prep = train_test_split(df, test_size=0.2, stratify=df[\"generated\"])\n",
    "valid_df, test_df = train_test_split(\n",
    "    val_prep, test_size=0.25, stratify=val_prep[\"generated\"]\n",
    ")\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "valid_df = valid_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "# First pass: gather all node types\n",
    "for _, row in train_df.iterrows():\n",
    "    tree = parser.parse(str.encode(row[\"text\"]))\n",
    "    types = []\n",
    "    walk_tree(tree.root_node, types)\n",
    "    node_types.update(types)\n",
    "\n",
    "# Create fixed feature vector mapping\n",
    "node_types = sorted(node_types)\n",
    "type_to_idx = {typ: i for i, typ in enumerate(node_types)}\n",
    "\n",
    "# X = torch.stack([code_to_feature_vector(train_df[\"text\"]) for code, _ in samples])\n",
    "# y = torch.tensor([label for _, label in samples], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "40914147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!=',\n",
       " '%',\n",
       " '%=',\n",
       " '&',\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '**',\n",
       " '*=',\n",
       " '+',\n",
       " '+=',\n",
       " ',',\n",
       " '-',\n",
       " '-=',\n",
       " '->',\n",
       " '.',\n",
       " '/',\n",
       " '//',\n",
       " '//=',\n",
       " '/=',\n",
       " ':',\n",
       " ':=',\n",
       " ';',\n",
       " '<',\n",
       " '<<',\n",
       " '<<=',\n",
       " '<=',\n",
       " '=',\n",
       " '==',\n",
       " '>',\n",
       " '>=',\n",
       " '>>',\n",
       " '>>=',\n",
       " '@',\n",
       " 'ERROR',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '^=',\n",
       " '_',\n",
       " 'and',\n",
       " 'argument_list',\n",
       " 'as',\n",
       " 'as_pattern',\n",
       " 'as_pattern_target',\n",
       " 'assert',\n",
       " 'assert_statement',\n",
       " 'assignment',\n",
       " 'attribute',\n",
       " 'augmented_assignment',\n",
       " 'binary_operator',\n",
       " 'block',\n",
       " 'boolean_operator',\n",
       " 'break',\n",
       " 'break_statement',\n",
       " 'call',\n",
       " 'case',\n",
       " 'class',\n",
       " 'class_definition',\n",
       " 'comment',\n",
       " 'comparison_operator',\n",
       " 'concatenated_string',\n",
       " 'conditional_expression',\n",
       " 'constrained_type',\n",
       " 'continue',\n",
       " 'continue_statement',\n",
       " 'def',\n",
       " 'default_parameter',\n",
       " 'del',\n",
       " 'delete_statement',\n",
       " 'dictionary',\n",
       " 'dictionary_comprehension',\n",
       " 'dotted_name',\n",
       " 'elif',\n",
       " 'elif_clause',\n",
       " 'else',\n",
       " 'else_clause',\n",
       " 'escape_sequence',\n",
       " 'except',\n",
       " 'expression_list',\n",
       " 'expression_statement',\n",
       " 'false',\n",
       " 'float',\n",
       " 'for',\n",
       " 'for_in_clause',\n",
       " 'for_statement',\n",
       " 'format_specifier',\n",
       " 'from',\n",
       " 'function_definition',\n",
       " 'generator_expression',\n",
       " 'generic_type',\n",
       " 'global',\n",
       " 'global_statement',\n",
       " 'identifier',\n",
       " 'if',\n",
       " 'if_clause',\n",
       " 'if_statement',\n",
       " 'import',\n",
       " 'import_from_statement',\n",
       " 'import_statement',\n",
       " 'in',\n",
       " 'integer',\n",
       " 'interpolation',\n",
       " 'is',\n",
       " 'is not',\n",
       " 'keyword_argument',\n",
       " 'lambda',\n",
       " 'lambda_parameters',\n",
       " 'list',\n",
       " 'list_comprehension',\n",
       " 'list_pattern',\n",
       " 'list_splat',\n",
       " 'list_splat_pattern',\n",
       " 'module',\n",
       " 'named_expression',\n",
       " 'none',\n",
       " 'nonlocal',\n",
       " 'nonlocal_statement',\n",
       " 'not',\n",
       " 'not in',\n",
       " 'not_operator',\n",
       " 'or',\n",
       " 'pair',\n",
       " 'parameters',\n",
       " 'parenthesized_expression',\n",
       " 'pass',\n",
       " 'pass_statement',\n",
       " 'pattern_list',\n",
       " 'print',\n",
       " 'print_statement',\n",
       " 'raise',\n",
       " 'raise_statement',\n",
       " 'return',\n",
       " 'return_statement',\n",
       " 'set',\n",
       " 'set_comprehension',\n",
       " 'slice',\n",
       " 'string',\n",
       " 'string_content',\n",
       " 'string_end',\n",
       " 'string_start',\n",
       " 'subscript',\n",
       " 'true',\n",
       " 'try',\n",
       " 'tuple',\n",
       " 'tuple_pattern',\n",
       " 'type',\n",
       " 'type_conversion',\n",
       " 'type_parameter',\n",
       " 'typed_parameter',\n",
       " 'unary_operator',\n",
       " 'while',\n",
       " 'while_statement',\n",
       " 'wildcard_import',\n",
       " 'with',\n",
       " 'with_clause',\n",
       " 'with_item',\n",
       " 'with_statement',\n",
       " 'yield',\n",
       " '{',\n",
       " '|',\n",
       " '|=',\n",
       " '}']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6474104a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            self.dataframe[\"text\"].iloc[index],\n",
    "            code_to_feature_vector(str.encode(self.dataframe[\"text\"].iloc[index])),\n",
    "            float(self.dataframe[\"generated\"].iloc[index]),\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "\n",
    "data_train = CustomDataset(dataframe=train_df)\n",
    "dataloader_train = DataLoader(data_train, batch_size=32)\n",
    "data_val = CustomDataset(dataframe=valid_df)\n",
    "dataloader_val = DataLoader(data_val, batch_size=32)\n",
    "data_test = CustomDataset(dataframe=test_df)\n",
    "dataloader_test = DataLoader(data_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1dde22ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 232/232 [00:02<00:00, 111.31it/s]\n",
      "100%|██████████| 44/44 [00:00<00:00, 122.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC=0.9836189442012511, F1=0.9816326530612245, recall=0.9717171717171718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 232/232 [00:02<00:00, 111.92it/s]\n",
      "100%|██████████| 44/44 [00:00<00:00, 121.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC=0.9961903469182304, F1=0.993963782696177, recall=0.997979797979798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 232/232 [00:02<00:00, 110.18it/s]\n",
      "100%|██████████| 44/44 [00:00<00:00, 126.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC=0.9973101677468978, F1=0.9959677419354839, recall=0.997979797979798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 232/232 [00:02<00:00, 108.79it/s]\n",
      "100%|██████████| 44/44 [00:00<00:00, 120.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC=0.9977603583426652, F1=0.9959758551307847, recall=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 232/232 [00:02<00:00, 112.29it/s]\n",
      "100%|██████████| 44/44 [00:00<00:00, 123.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC=0.9919305032406935, F1=0.9879518072289156, recall=0.9939393939393939\n",
      "Final Loss: 7.1997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import f1_score, recall_score, roc_auc_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class CodeClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=32):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, 1)  # binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.fc2(self.relu(self.fc1(x))))\n",
    "\n",
    "\n",
    "model = CodeClassifier(input_dim=len(node_types))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Simple training loop\n",
    "for epoch in range(5):\n",
    "    model.train()\n",
    "    for _, text, label in tqdm(dataloader_train):\n",
    "        outputs = model(text)\n",
    "        outputs = outputs.squeeze()\n",
    "        loss = criterion(outputs, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        all_predictions = []\n",
    "        all_truths = []\n",
    "        for _, text, label in tqdm(dataloader_val):\n",
    "            outputs = model(text)\n",
    "            outputs = outputs.squeeze()\n",
    "\n",
    "            all_predictions.extend(outputs.numpy().tolist())\n",
    "            all_truths.extend(label.numpy().tolist())\n",
    "\n",
    "        rounded = [round(x) for x in all_predictions]\n",
    "        all_truths = [round(x) for x in all_truths]\n",
    "\n",
    "        score = roc_auc_score(all_truths, rounded)\n",
    "        f1 = f1_score(all_truths, rounded)\n",
    "        recall = recall_score(all_truths, rounded)\n",
    "        print(f\"ROC-AUC={score}, F1={f1}, recall={recall}\")\n",
    "\n",
    "\n",
    "print(f\"Final Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "54f6c54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 120.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE=0.006881102376334462, MSE=0.005617118145371848\n",
      "ROC-AUC=0.9919361399227171, F1=0.9879518072289156, recall=0.9939393939393939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "with torch.no_grad():\n",
    "    all_predictions = []\n",
    "    all_truths = []\n",
    "    all_real_texts = []\n",
    "    for real_text, text, label in tqdm(dataloader_test):\n",
    "        outputs = model(text)\n",
    "        outputs = outputs.squeeze()\n",
    "\n",
    "        all_real_texts.extend(real_text)\n",
    "        all_predictions.extend(outputs.numpy().tolist())\n",
    "        all_truths.extend(label.numpy().tolist())\n",
    "\n",
    "    print(\n",
    "        f\"MAE={mean_absolute_error(all_predictions, all_truths)}, MSE={mean_squared_error(all_predictions, all_truths)}\"\n",
    "    )\n",
    "\n",
    "    rounded = [round(x) for x in all_predictions]\n",
    "    all_truths = [round(x) for x in all_truths]\n",
    "\n",
    "    score = roc_auc_score(all_truths, rounded)\n",
    "    f1 = f1_score(all_truths, rounded)\n",
    "    recall = recall_score(all_truths, rounded)\n",
    "    print(f\"ROC-AUC={score}, F1={f1}, recall={recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f5d95348",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(\n",
    "    {\"code\": all_real_texts, \"real\": all_truths, \"predicted\": all_predictions}\n",
    ")\n",
    "res.to_csv(\"ast.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f1d6d1bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "463"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "27c11677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>real</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>keyboard = {\\n    'a': 's', 's': 'd', 'd': 'f'...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>print(len(input().split()))</td>\n",
       "      <td>0</td>\n",
       "      <td>5.463030e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>print(len(input().split()))</td>\n",
       "      <td>0</td>\n",
       "      <td>5.463030e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>\\r\\nv = int(input(\"\\nv - bus speed,\\r\\n\"))\\r\\n...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.562366e-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  code  real     predicted\n",
       "123  keyboard = {\\n    'a': 's', 's': 'd', 'd': 'f'...     0  1.000000e+00\n",
       "178                        print(len(input().split()))     0  5.463030e-01\n",
       "326                        print(len(input().split()))     0  5.463030e-01\n",
       "353  \\r\\nv = int(input(\"\\nv - bus speed,\\r\\n\"))\\r\\n...     1  2.562366e-12"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = res[abs(res[\"predicted\"] - res[\"real\"]) >= 0.3]\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "522e8bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "v = int(input(\"\\nv - bus speed,\\r\\n\"))\n",
      "t = int(input(\"\\nt - travel time.\\r\\n\"))\n",
      "distance = v * t\n",
      "print(distance)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(str(new_df[\"code\"].iloc[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a29df5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "code1 = \"\"\"\n",
    "a,b = map(int, input().split())\n",
    "if a > b:\n",
    "    return 1\n",
    "return 0\n",
    "\"\"\"\n",
    "\n",
    "code2 = \"\"\"\n",
    "x, y = map(int, input().split())\n",
    "return int(x>y)\n",
    "\"\"\"\n",
    "\n",
    "code3 = \"\"\"\n",
    "l = map(int, input().split())\n",
    "if l[0] > l[1] :\n",
    "    return 1\n",
    "else:\n",
    "    return 0\n",
    "\"\"\"\n",
    "\n",
    "vec1 = code_to_feature_vector(str.encode(code1))\n",
    "vec2 = code_to_feature_vector(str.encode(code2))\n",
    "vec3 = code_to_feature_vector(str.encode(code3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0e093629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9536)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec1.dot(vec2) / vec1.norm() / vec2.norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ec442eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8293)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec3.dot(vec2) / vec3.norm() / vec2.norm()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
